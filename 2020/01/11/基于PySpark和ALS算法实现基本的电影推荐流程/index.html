<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yield-bytes.gitee.io","root":"/blog/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","Pisces | Gemini":240,"width":300,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="&amp;#8195;&amp;#8195;本文内容第一部分给出Pyspark常见算子的用法，第二部分则参考书籍《Python spark2.0 Hadoop机器学习与大数据实战》的电影推荐章节。本文内容为大数据实时分析项目提供基本的入门知识。 1、PySpark简介&amp;#8195;&amp;#8195;本节内容的图文一部分参考了这篇文章《PySpark 的背后原理 》，个人欣赏此博客作者，博文质量高，看完受益匪浅！Spa">
<meta property="og:type" content="article">
<meta property="og:title" content="基于PySpark和ALS算法实现基本的电影推荐流程">
<meta property="og:url" content="https://yield-bytes.gitee.io/blog/2020/01/11/%E5%9F%BA%E4%BA%8EPySpark%E5%92%8CALS%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E6%B5%81%E7%A8%8B/index.html">
<meta property="og:site_name" content="yield-bytes">
<meta property="og:description" content="&amp;#8195;&amp;#8195;本文内容第一部分给出Pyspark常见算子的用法，第二部分则参考书籍《Python spark2.0 Hadoop机器学习与大数据实战》的电影推荐章节。本文内容为大数据实时分析项目提供基本的入门知识。 1、PySpark简介&amp;#8195;&amp;#8195;本节内容的图文一部分参考了这篇文章《PySpark 的背后原理 》，个人欣赏此博客作者，博文质量高，看完受益匪浅！Spa">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200108220627968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200108215814813.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200109205253156.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200109204624664.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200111095444386.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200111100116354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2020-01-11T02:23:19.000Z">
<meta property="article:modified_time" content="2020-02-03T03:55:10.000Z">
<meta property="article:tag" content="Spark">
<meta property="article:tag" content="PySpark推荐">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200108220627968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">

<link rel="canonical" href="https://yield-bytes.gitee.io/blog/2020/01/11/%E5%9F%BA%E4%BA%8EPySpark%E5%92%8CALS%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E6%B5%81%E7%A8%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>基于PySpark和ALS算法实现基本的电影推荐流程 | yield-bytes</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/blog/atom.xml" title="yield-bytes" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">yield-bytes</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">分享与沉淀</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-th-large fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://gitee.com/yield-bytes" class="github-corner" title="Follow me on Gitee" aria-label="Follow me on Gitee" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yield-bytes.gitee.io/blog/2020/01/11/%E5%9F%BA%E4%BA%8EPySpark%E5%92%8CALS%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E6%B5%81%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://www.linuxprobe.com/wp-content/uploads/2018/06/QQ%E5%9B%BE%E7%89%8720180625205006.png">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="一个非常专注技术总结与分享的博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yield-bytes">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基于PySpark和ALS算法实现基本的电影推荐流程
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-11 10:23:19" itemprop="dateCreated datePublished" datetime="2020-01-11T10:23:19+08:00">2020-01-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-03 11:55:10" itemprop="dateModified" datetime="2020-02-03T11:55:10+08:00">2020-02-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>24k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>21 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>&#8195;&#8195;本文内容第一部分给出Pyspark常见算子的用法，第二部分则参考书籍《Python spark2.0 Hadoop机器学习与大数据实战》的电影推荐章节。本文内容为大数据实时分析项目提供基本的入门知识。</p>
<h4 id="1、PySpark简介"><a href="#1、PySpark简介" class="headerlink" title="1、PySpark简介"></a>1、PySpark简介</h4><p>&#8195;&#8195;本节内容的图文一部分参考了这篇文章<a target="_blank" rel="noopener" href="http://sharkdtu.com/posts/pyspark-internal.html">《PySpark 的背后原理 》</a>，个人欣赏此博客作者，博文质量高，看完受益匪浅！Spark的内容不再累赘，可参考本博客<a target="_blank" rel="noopener" href="https://blog.csdn.net/pysense/article/details/103641824">《深入理解Spark》</a>。PySpark的工作原理图示如下：<br><img src="https://img-blog.csdnimg.cn/20200108220627968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<p>&#8195;&#8195;在这里，Py4J 是一个用 Python 和 Java 编写的库，它可以让Python代码实现动态访问JVM的Java对象，同时JVM也能够回调 Python对象。因此PySpark就是在Spark外围包装一层Python API，借助Py4j实现Python和Java的交互（这里的交互就是通过socket实现，传字节码），进而实现通过Python编写Spark应用程序。<br><img src="https://img-blog.csdnimg.cn/20200108215814813.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">&#8195;&#8195;在Driver端，PySparkContext通过Py4J启动一个JVM并产生一个JavaSparkContext；在Executor端，则不需要借助Py4j，因为Executor端运行的是由Driver传过来的Task业务逻辑（其实就是java的字节码）。</p>
<h4 id="2、Pyspark接口用法"><a href="#2、Pyspark接口用法" class="headerlink" title="2、Pyspark接口用法"></a>2、Pyspark接口用法</h4><h5 id="读取数据源"><a href="#读取数据源" class="headerlink" title="读取数据源"></a>读取数据源</h5><p>PySpark支持多种数据源读取，常见接口如下： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sc.pickleFile() <span class="comment"># &lt;class &#x27;pyspark.rdd.RDD&#x27;&gt;</span></span><br><span class="line">sc.textFile() <span class="comment"># &lt;class &#x27;pyspark.rdd.RDD&#x27;&gt;</span></span><br><span class="line">spark.read.json() <span class="comment"># &lt;class &#x27;pyspark.sql.dataframe.DataFrame&#x27;&gt;</span></span><br><span class="line">spark.read.text() <span class="comment"># &lt;class &#x27;pyspark.sql.dataframe.DataFrame&#x27;&gt;</span></span><br></pre></td></tr></table></figure>
<p>例如读取本地要注意，格式为<code>file://+文件绝对路径</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.textFile(<span class="string">&quot;file:///home/mparsian/dna_seq.txt&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取hdfs上文件数据</span></span><br><span class="line">sc.textFile(<span class="string">&quot;your_hadoop/data/moves.txt&quot;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="常用算子"><a href="#常用算子" class="headerlink" title="常用算子"></a>常用算子</h5><p>Spark的算子分为两类：Transformation和Action。<br>Transformation仅仅是定义逻辑，并不会立即执行，有lazy特性，目的是将一个RDD转为新的RDD，可以基于RDDs形成lineage（DAG图）；<br>Action：触发Job运行，真正触发driver运行job；</p>
<p><strong>第一类算子：Transformation</strong></p>
<ul>
<li>map(func): 返回一个新的RDD，func会作用于每个map的key，例如在wordcount例子要<code>rdd.map(lambda a, (a, 1))</code>将数据转换成(a, 1)的形式以便之后做reduce<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">word_rdd = sc.parallelize (</span><br><span class="line">   [<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;foo&quot;</span>, <span class="string">&quot;pyspark&quot;</span>, <span class="string">&quot;kafka&quot;</span>,<span class="string">&quot;kafka&quot;</span>, <span class="number">10</span>,<span class="number">10</span>]</span><br><span class="line">   )</span><br><span class="line">word_map_rdd = word_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> w: (w, <span class="number">1</span>))</span><br><span class="line">mapping = word_map_rdd.collect()</span><br><span class="line">print(mapping)</span><br><span class="line"><span class="comment">#输出</span></span><br><span class="line">[(<span class="string">&#x27;foo&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;foo&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;pyspark&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;kafka&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;kafka&#x27;</span>, <span class="number">1</span>), (<span class="number">10</span>, <span class="number">1</span>), (<span class="number">10</span>, <span class="number">1</span>)]</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li> mappartitions(func, partition):  Return a new RDD by applying a function to each partition of this RDD.和map不同的地方在于map的func应用于每个元素，而这里的func会应用于每个分区，能够有效减少调用开销，减少func初始化次数。减少了初始化的内存开销。<br>例如将一个数据集合分成2个区，再对每个区进行累加，该方法适合对超大数据集合的分区累加处理，例如有1亿个item，分成100个分区，有10台服务器，那么每台服务器就可以负责自己10个分区的数据累加处理。<br>官方也提到mappartitions中如果一个分区太大，一次计算的话可能直接导致内存溢出。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([<span class="number">10</span>, <span class="number">22</span>, <span class="number">3</span>, <span class="number">4</span>], <span class="number">2</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">each_partition</span>):</span> </span><br><span class="line"><span class="keyword">yield</span> <span class="built_in">sum</span>(each_partition)</span><br><span class="line">rdd.glom().collect()</span><br><span class="line"><span class="comment">#输出：</span></span><br><span class="line">[[<span class="number">10</span>, <span class="number">22</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">rdd.mapPartitions(f).glom().collect()</span><br><span class="line">[[<span class="number">32</span>], [<span class="number">7</span>]]</span><br></pre></td></tr></table></figure>




<ul>
<li><p>filter(func): 返回一个新的RDD，func会作用于每个map的key，用于筛选数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize ([<span class="string">&quot;fooo&quot;</span>, <span class="string">&quot;bbbar&quot;</span>, <span class="string">&quot;foo&quot;</span>, <span class="string">&quot; &quot;</span>, <span class="string">&quot;Aoo&quot;</span>])</span><br><span class="line">rdd.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: <span class="string">&#x27;foo&#x27;</span> <span class="keyword">in</span> x).collect()</span><br><span class="line"><span class="comment"># [&#x27;fooo&#x27;, &#x27;foo&#x27;]</span></span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li>flatMap(func): 返回一个新的RDD，func用在每个item，并把item切分为多个元素返回，例如wordcount例子的分类<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize ([<span class="string">&quot;this is pyspark&quot;</span>, <span class="string">&quot;this is spark&quot;</span>])</span><br><span class="line">rdd.flatMap(<span class="keyword">lambda</span> line:line.split(<span class="string">&#x27; &#x27;</span>)).collect()</span><br><span class="line"><span class="comment">#可以看到每个item为一句话，经过func后，分解为多个单词（多个元素）</span></span><br><span class="line"><span class="comment"># [&#x27;this&#x27;, &#x27;is&#x27;, &#x27;pyspark&#x27;, &#x27;this&#x27;, &#x27;is&#x27;, &#x27;spark&#x27;]</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize ((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">rdd.flatMap(<span class="keyword">lambda</span> x:(<span class="number">2</span>*x,<span class="number">3</span>*x)).collect()</span><br><span class="line"><span class="comment"># 对原来每个item分别乘2乘3，func返回两个item</span></span><br><span class="line"><span class="comment"># [2, 3, 4, 6, 6, 9]</span></span><br></pre></td></tr></table></figure>


<ul>
<li>flatMapValues(func)：flatMapValues类似于mapValues，不同的在于flatMapValues应用于元素为key-value对的RDD中Value。每个一kv对的Value被输入函数映射为一系列的值，然后这些值再与原RDD中的Key组成一系列新的KV对。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;name&quot;</span>, [<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;aoo&quot;</span>]), (<span class="string">&quot;age&quot;</span>, [<span class="string">&quot;12&quot;</span>, <span class="string">&quot;20&quot;</span>])])</span><br><span class="line">rdd.flatMapValues(<span class="keyword">lambda</span> x:x).collect()</span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">[(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>),</span><br><span class="line"> (<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>),</span><br><span class="line"> (<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;aoo&#x27;</span>),</span><br><span class="line"> (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;12&#x27;</span>),</span><br><span class="line"> (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;20&#x27;</span>)]</span><br></pre></td></tr></table></figure>



<ul>
<li><p>mapValues(func): 返回一个新的RDD，对RDD中的每一个value应用函数func。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;name&quot;</span>, [<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;aoo&quot;</span>]), (<span class="string">&quot;age&quot;</span>, [<span class="string">&quot;12&quot;</span>, <span class="string">&quot;20&quot;</span>])])</span><br><span class="line">rdd.mapValues(<span class="keyword">lambda</span> value:<span class="built_in">len</span>(value)).collect()</span><br><span class="line"><span class="comment"># [(&#x27;name&#x27;, 3), (&#x27;age&#x27;, 2)]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>distinct(): 去除重复的元素</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd.distinct().collect()</span><br><span class="line"><span class="comment"># [(&#x27;a&#x27;, 1), (&#x27;a&#x27;, 10), (&#x27;b&#x27;, 1)]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>subtractByKey(other): 删除在RDD1与RDD2的key相同的项</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd1 = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd2 = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;c&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd1.subtractByKey(rdd2).collect()</span><br><span class="line"><span class="comment"># [(&#x27;b&#x27;, 1)]</span></span><br></pre></td></tr></table></figure>

<ul>
<li>subtract(other): 取差集<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd1 = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd2 = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;c&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd1.subtract(rdd2).collect()</span><br><span class="line"><span class="comment"># [(&#x27;b&#x27;, 1)]</span></span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li>intersection(other): 交集运算，保留在两个RDD中都有的元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd1 = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd2 = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;c&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd1.intersection(rdd2).collect()</span><br><span class="line"><span class="comment"># [(&#x27;a&#x27;, 1), (&#x27;a&#x27;, 10)]</span></span><br></pre></td></tr></table></figure>

<p>有关key-value类型的处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line"><span class="comment"># 取出所有item的key</span></span><br><span class="line">rdd.keys().collect() <span class="comment"># [&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;a&#x27;]</span></span><br><span class="line"><span class="comment"># 取出所有的values</span></span><br><span class="line">rdd.values().collect() <span class="comment"># [1, 10, 1, 1]</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>foldByKey</code>(<em>zeroValue</em>, <em>func</em>, <em>numPartitions=None</em>)</p>
<p>Merge the values for each  key using an associative function “func” and a neutral “zeroValue” which  may be added to the result an arbitrary number of times, and must not  change the result (e.g., 0 for addition, or  1 for multiplication.).<br>其实foldByKey也像reduceBykey，对同一key中的value进行合并，例如对相同key进行value累加，zeroValue=0表示累加：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd.foldByKey(<span class="number">0</span>, <span class="keyword">lambda</span> x,y:x+y).collect()</span><br><span class="line"><span class="comment"># [(&#x27;a&#x27;, 2), (&#x27;b&#x27;, 1)]</span></span><br></pre></td></tr></table></figure>


</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对相同key进行value累乘，注意zeroValue=1代表累乘：</span></span><br><span class="line">rdd = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>)])</span><br><span class="line">rdd.foldByKey(<span class="number">1</span>, <span class="keyword">lambda</span> x,y:x*y).collect()</span><br><span class="line"><span class="comment"># [(&#x27;a&#x27;, 4), (&#x27;b&#x27;, 1)]</span></span><br></pre></td></tr></table></figure>


<ul>
<li>groupByKey(numPartitions=None): 将(K, V)数据集上所有Key相同的数据聚合到一起，得到的结果是(K, (V1, V2…))<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line"><span class="built_in">sorted</span>(rdd.groupByKey().mapValues(<span class="built_in">len</span>).collect())</span><br><span class="line"><span class="comment"># 统计数据集每个key的个数总和</span></span><br><span class="line"><span class="comment"># [(&#x27;a&#x27;, 3), (&#x27;b&#x27;, 1)]</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line"><span class="built_in">sorted</span>(rdd.groupByKey().mapValues(<span class="built_in">list</span>).collect())</span><br><span class="line"><span class="comment"># 将每个key的v聚合到一个list里面</span></span><br><span class="line"><span class="comment"># [(&#x27;a&#x27;, [1, 10, 1]), (&#x27;b&#x27;, [1])]</span></span><br></pre></td></tr></table></figure>

<ul>
<li>reduceByKey(func, numPartitions=None):此算子最常用， 将(K,  V)数据集上所有Key相同的数据聚合到一起，func的参数即是每两个K-V中的V。可以使用这个函数来进行计数，例如reduceByKey(lambda  a,b:a+b)就是将key相同数据的Value进行相加。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;foo&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;foo&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;bar&quot;</span>, <span class="number">3</span>)])</span><br><span class="line">rdd.reduceByKey(<span class="keyword">lambda</span> x, y : x + y).collect() <span class="comment"># [(&#x27;foo&#x27;, 3), (&#x27;bar&#x27;, 3)]  </span></span><br><span class="line">x.reduceByKey(<span class="built_in">max</span>).collect() <span class="comment">#  [(&#x27;foo&#x27;, 2), (&#x27;bar&#x27;, 3)]</span></span><br></pre></td></tr></table></figure>



<ul>
<li>join(other, numPartitions=None): 将(K, V)和(K, W)类型的数据进行JOIN操作，得到的结果是这样(K, (V, W))</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd1 = sc.parallelize([(<span class="string">&quot;bar&quot;</span>, <span class="number">10</span>) , (<span class="string">&quot;foo&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd2 = sc.parallelize([(<span class="string">&quot;bar&quot;</span>, <span class="number">12</span>) , (<span class="string">&quot;foo&quot;</span>, <span class="number">12</span>)])</span><br><span class="line">rdd1.join(rdd2).collect()</span><br><span class="line"><span class="comment"># [(&#x27;bar&#x27;, (10, 12)), (&#x27;foo&#x27;, (1, 12))]</span></span><br></pre></td></tr></table></figure>


<ul>
<li>union(other): 并集运算，合并两个RDD</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd1 &#x3D; sc.parallelize([(&quot;a&quot;, 10) ,(&quot;b&quot;, 1), (&quot;a&quot;, 1)])</span><br><span class="line">rdd2 &#x3D; sc.parallelize([(&quot;a&quot;, 10) ,(&quot;c&quot;, 1), (&quot;a&quot;, 1)])</span><br><span class="line">rdd1.union(rdd2).collect()</span><br><span class="line"># [(&#39;a&#39;, 10), (&#39;b&#39;, 1), (&#39;a&#39;, 1), (&#39;a&#39;, 10), (&#39;c&#39;, 1), (&#39;a&#39;, 1)]</span><br></pre></td></tr></table></figure>
<p>还有更多的transmission算子这里不再一一列举，可以参考官网PySpark API文档。</p>
<p>第二类算子：Action</p>
<ul>
<li><p>collect(): 以数组的形式，返回数据集中所有的元素。在数据探索阶段常用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">word_rdd = sc.parallelize (</span><br><span class="line">   [<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;foo&quot;</span>, <span class="string">&quot;pyspark&quot;</span>, <span class="string">&quot;kafka&quot;</span>,<span class="string">&quot;kafka&quot;</span>, <span class="number">10</span>,<span class="number">10</span>]</span><br><span class="line">)</span><br><span class="line">word_map_rdd = word_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> w: (w, <span class="number">1</span>))</span><br><span class="line">word_map_rdd.collect()</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">[(<span class="string">&#x27;foo&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;foo&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;pyspark&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;kafka&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;kafka&#x27;</span>, <span class="number">1</span>), (<span class="number">10</span>, <span class="number">1</span>), (<span class="number">10</span>, <span class="number">1</span>)]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>collectAsMap将k-v数据rdd集合转为python字典类型，同一key的项，只取第一项，其他的项被忽略</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>) ,(<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd.collectAsMap() <span class="comment"># &#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: 1&#125;</span></span><br></pre></td></tr></table></figure></li>
<li><p>count(): 返回数据集中元素的个数</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">word_rdd = sc.parallelize (</span><br><span class="line">   [<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;foo&quot;</span>, <span class="string">&quot;pyspark&quot;</span>, <span class="string">&quot;kafka&quot;</span>,<span class="string">&quot;kafka&quot;</span>, <span class="number">10</span>,<span class="number">10</span>]</span><br><span class="line">)</span><br><span class="line">word_rdd.count() <span class="comment"># 8</span></span><br></pre></td></tr></table></figure>

<ul>
<li>take(n): 返回数据集的前N个元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">word_rdd = sc.parallelize (</span><br><span class="line">   [<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;foo&quot;</span>, <span class="string">&quot;pyspark&quot;</span>, <span class="string">&quot;kafka&quot;</span>,<span class="string">&quot;kafka&quot;</span>, <span class="number">10</span>,<span class="number">10</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">word_rdd.take(<span class="number">3</span>) <span class="comment"># [&#x27;foo&#x27;, &#x27;bar&#x27;, &#x27;foo&#x27;]</span></span><br></pre></td></tr></table></figure>

<ul>
<li>takeOrdered(n): 升序排列，取出前N个元素<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">word_rdd = sc.parallelize (</span><br><span class="line">   [<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;foo&quot;</span>, <span class="string">&quot;zoo&quot;</span>, <span class="string">&quot;aoo&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">word_rdd.takeOrdered(<span class="number">3</span>) <span class="comment"># [&#x27;aoo&#x27;, &#x27;bar&#x27;, &#x27;foo&#x27;]</span></span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li>takeOrdered(n, key=lambda num: -num): 降序排列，取出前N个元素<br>key=lambda num: -num只适用数值型的rdd，其实就将每项数值变为负数再排列</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd=sc.parallelize([<span class="number">10</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>], <span class="number">2</span>).takeOrdered(<span class="number">3</span>,key=<span class="keyword">lambda</span> num:-num)</span><br><span class="line">print(rdd)</span><br></pre></td></tr></table></figure>
<p>字符串的rdd排序，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">word_rdd = sc.parallelize (</span><br><span class="line">   [<span class="string">&quot;fooo&quot;</span>, <span class="string">&quot;bbbar&quot;</span>, <span class="string">&quot;ffoo&quot;</span>, <span class="string">&quot;zoo&quot;</span>, <span class="string">&quot;aoo&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按字符长度降序排序再取前3项</span></span><br><span class="line">word_rdd.takeOrdered(<span class="number">3</span>,key=<span class="keyword">lambda</span> item:-<span class="built_in">len</span>(item))</span><br><span class="line"><span class="comment"># 按字符长度升序排序再取前3项</span></span><br><span class="line">word_rdd.takeOrdered(<span class="number">3</span>,key=<span class="built_in">len</span>)</span><br><span class="line"><span class="comment">#按字母升序排序再取前3项</span></span><br><span class="line">word_rdd.takeOrdered(<span class="number">3</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ul>
<li><p>countByKey(): 对同一key值累计其计数，例如wordcount</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">&quot;foo&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;bar&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;foo&quot;</span>, <span class="number">1</span>)])</span><br><span class="line">rdd.countByKey().items()</span><br><span class="line"><span class="comment"># dict_items([(&#x27;foo&#x27;, 2), (&#x27;bar&#x27;, 1)])以元组的方式返回</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>countByValue():对值分组统计</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd=sc.parallelize([<span class="number">9</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>])</span><br><span class="line">rdd.countByValue().items()</span><br><span class="line"><span class="comment"># dict_items([(9, 2), (10, 3)])</span></span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><p>Persistence(持久化)<br>persist(): 将数据按默认的方式进行持久化<br> unpersist(): 取消持久化<br>saveAsTextFile(path): 将数据集保存至文件</p>
</li>
<li><p>创建rdd对象时指定分区，<br><code>parallelize(c, numSlices=None)</code><br>对每个元素都分区</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sc.parallelize([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>], <span class="number">5</span>).glom().collect()</span><br><span class="line"><span class="comment"># [[0], [2], [3], [4], [6]]</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>glom方法：Return an RDD created by coalescing all elements within each partition into a list<br>指定两个分区</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd=sc.parallelize([<span class="number">10</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>], <span class="number">2</span>)</span><br><span class="line">rdd.glom().collect()</span><br><span class="line">[[<span class="number">10</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">9</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]]</span><br></pre></td></tr></table></figure>



<ul>
<li>广播rdd<br>给定一个key为id的字段数据集合，给定其id，求字段对应的value</li>
</ul>
<p>非广播方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apples = sc.parallelize([(<span class="number">1</span>, <span class="string">&#x27;iPhone X&#x27;</span>),(<span class="number">2</span>, <span class="string">&#x27;iPhone 8&#x27;</span>),(<span class="number">5</span>, <span class="string">&#x27;iPhone 11&#x27;</span>)])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>将该数据集合转为字典</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apples_dict=apples.collectAsMap()</span><br><span class="line"><span class="comment"># &#123;1: &#x27;iPhone X&#x27;, 2: &#x27;iPhone 8&#x27;, 5: &#x27;iPhone 11&#x27;&#125;</span></span><br></pre></td></tr></table></figure>

<p>给定id集合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ids = sc.parallelize([<span class="number">2</span>,<span class="number">1</span>,<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<p>通过map方法取出ids对应的value</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ids.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:apples_dict[x]).collect()</span><br><span class="line"><span class="comment"># [&#x27;iPhone 8&#x27;, &#x27;iPhone X&#x27;, &#x27;iPhone 11&#x27;]</span></span><br></pre></td></tr></table></figure>

<p>这种方式，在ids与apples_dict之间的映射转换，每一个id查找映射，都需要将ids和apples_dict传到worker节点上计算，如果有100万个id，而且apples_dict是个超大字典，那么就需要进行100万次上传worker再计算结果，显然效率极低，也不合理。</p>
<p>使用广播方式可避免这种情况<br>将apples_dict转为广播变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apples_dict_bc=sc.broadcast(apples_dict)</span><br><span class="line">print(<span class="built_in">type</span>(apples_dict_bc))</span><br><span class="line"><span class="comment"># &lt;class &#x27;pyspark.broadcast.Broadcast&#x27;&gt;</span></span><br></pre></td></tr></table></figure>
<p>给定id集合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ids = sc.parallelize([<span class="number">2</span>,<span class="number">1</span>,<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<p>id对应的value，使用apples_dict_bc.value[x]这个广播变量，获取id对应的value</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ids.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:apples_dict_bc.value[x]).collect()</span><br><span class="line"><span class="comment"># [&#x27;iPhone 8&#x27;, &#x27;iPhone X&#x27;, &#x27;iPhone 11&#x27;]</span></span><br></pre></td></tr></table></figure>

<p>在开始计算时，apples_dict_bc会传到worker node的内存上（如果数据集合太大，有部分数据则存在磁盘）。之后worker 可以一直使用这个“常驻内存广播变量”处理映射任务，即使有100万个id，客户端只需要把id传到worker即可，这个大apples_dict_bc数据集合则无需再传送到worker，大大减少时间。</p>
<ul>
<li>累加器accumulator：</li>
</ul>
<p>创建测试数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<p>创建accumulator累加器total，用于累加数集合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total=sc.accumulator(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>创建accumulator累加器counter，用于计数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">counter=sc.accumulator(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>使用foreach，对每一项都使用total累计该元素的值，counter累加已处理的元素个数，注意：counter这个accumulator变量是自增1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.foreach(<span class="keyword">lambda</span> item:[total.add(item),counter.add(<span class="number">1</span>)])</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">total.value # 15.0</span><br><span class="line">counter.value 5</span><br></pre></td></tr></table></figure>

<h5 id="完整的wordcount示例"><a href="#完整的wordcount示例" class="headerlink" title="完整的wordcount示例"></a>完整的wordcount示例</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyspark</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext <span class="keyword">as</span> sc</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_spark_context</span>()</span></span><br><span class="line">    conf=SparkConf().setAppName(&quot;word_count&quot;).setMaster(&quot;local[*]&quot;)</span><br><span class="line">    spark_context=sc.getOrCreate(conf)    </span><br><span class="line">    <span class="keyword">return</span> spark_context</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_count</span>(<span class="params">spark_sc,input_file,output_dir,delimiter=<span class="string">&#x27; &#x27;</span></span>):</span></span><br><span class="line">    data_rdd=spark_sc.textFile(input_file) <span class="comment"># </span></span><br><span class="line">    word_rdd=text_rdd.flatMap(<span class="keyword">lambda</span> line:line.split(delimiter))</span><br><span class="line">    count_rdd=word_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> word:(word,<span class="number">1</span>)).reduceByKey(<span class="keyword">lambda</span> v1,v2:v1+v2)</span><br><span class="line">    count_rdd.saveAsTextFile(output_dir) <span class="comment">#注意这里参数为文件夹 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    sc_obj=create_spark_context()</span><br><span class="line">    word_count(sc_obj,<span class="string">&quot;file:///opt/data.txt&quot;</span>,<span class="string">&quot;file:///opt/word_count_output&quot;</span>)</span><br></pre></td></tr></table></figure>


<p>查看存放的输出结果，计算结果的输出文件放在part-00000这个文件，而_SUCCESS文件是无内容的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@nn opt]<span class="comment"># ls word_count_output/</span></span><br><span class="line">part-<span class="number">00000</span>  _SUCCESS</span><br><span class="line"></span><br><span class="line">[root@nn word_count_output]<span class="comment"># cat part-00000 </span></span><br><span class="line">(<span class="string">&#x27;linux&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="string">&#x27;is&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="string">&#x27;the&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="string">&#x27;best&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="string">&#x27;centos&#x27;</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="string">&#x27;macos&#x27;</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="string">&#x27;redhat&#x27;</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>


<h4 id="3、基于PySpark和ALS的电影推荐流程"><a href="#3、基于PySpark和ALS的电影推荐流程" class="headerlink" title="3、基于PySpark和ALS的电影推荐流程"></a>3、基于PySpark和ALS的电影推荐流程</h4><p>&#8195;&#8195;本节内容参考书籍pdf版本《Python spark2.0 Hadoop机器学习与大数据实战》的电影推荐章节。<br>&#8195;&#8195;(有一点需要指出的是：该书的作者似乎为出书而出书，在前面十来章内容，冗长且基础，大量截图以及table，其实大部分内容可言简意赅。但他们似乎为了出书为了销量，需把这本书打造“很厚，页数多，专业技术书籍”的印象，但其精华只有后面关于pyspark.mllib机器学习示例的内容。)</p>
<h5 id="数据集背景"><a href="#数据集背景" class="headerlink" title="数据集背景"></a>数据集背景</h5><p>数据源：<code>https://grouplens.org/datasets/movielens/</code><br>这里有非常详细的电影训练数据，适合项目练手<br>数据信息：<br>MovieLens 100K<br>movie ratings.<br>Stable benchmark dataset. 100,000 ratings from 1000 users on 1700 movies</p>
<p>数据样例结构：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@nn ml-100k]# ls</span><br><span class="line">allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base  u.genre  u.occupation</span><br><span class="line">mku.sh     u1.test  u3.base  u4.test  ua.base  ub.test  u.info   u.user</span><br><span class="line">README     u2.base  u3.test  u5.base  ua.test  u.data   u.item</span><br></pre></td></tr></table></figure>

<p>有关数据结构的说明，可以查看README文件，例如u.data:4个字段，user id | item id | rating | timestamp.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">196     242     3       881250949</span><br><span class="line">186     302     3       891717742</span><br></pre></td></tr></table></figure>

<h5 id="读取用户数据"><a href="#读取用户数据" class="headerlink" title="读取用户数据"></a>读取用户数据</h5><p>探索基本数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">user_rdd=sc.textFile(<span class="string">&quot;file:///opt/ml-100k/u.data&quot;</span>)</span><br><span class="line">user_rdd.count()<span class="comment"># 100000</span></span><br><span class="line">user_rdd.first() <span class="comment"># &#x27;196\t242\t3\t881250949&#x27;</span></span><br></pre></td></tr></table></figure>
<p>因ALS入参为3个字段，故只需取出user_rdd前3个字段的:用户id，产品id以及评分:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">raw_rating_rdd=user_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line:line.split(<span class="string">&#x27;\t&#x27;</span>)[:<span class="number">3</span>]) <span class="comment"># 每行分割后为一个包含4个元素的列表，取前3项即可</span></span><br><span class="line">raw_rating_rdd.take(<span class="number">2</span>)</span><br><span class="line">输出：</span><br><span class="line">[[<span class="string">&#x27;196&#x27;</span>, <span class="string">&#x27;242&#x27;</span>, <span class="string">&#x27;3&#x27;</span>],[<span class="string">&#x27;186&#x27;</span>, <span class="string">&#x27;302&#x27;</span>, <span class="string">&#x27;3&#x27;</span>]] <span class="comment"># 注意，每个item是列表</span></span><br></pre></td></tr></table></figure>

<p>ALS训练数据格式的入参为一组元组类型的数据：Rating(user,product,rating)，过还需做以下转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rating_rdd=raw_rating_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(x[<span class="number">0</span>],x[<span class="number">1</span>],x[<span class="number">2</span>]))<span class="comment"># x[0],x[1],x[2]对应用户id，电影id，评分</span></span><br><span class="line">rating_rdd.take(<span class="number">2</span>)</span><br><span class="line">输出：</span><br><span class="line">[(<span class="string">&#x27;196&#x27;</span>, <span class="string">&#x27;242&#x27;</span>, <span class="string">&#x27;3&#x27;</span>), (<span class="string">&#x27;186&#x27;</span>, <span class="string">&#x27;302&#x27;</span>, <span class="string">&#x27;3&#x27;</span>)]<span class="comment"># rdd的每个item为元组类型</span></span><br></pre></td></tr></table></figure>

<p>查看不重复的用户总量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">total_users=rating_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">0</span>]).distinct().count()</span><br><span class="line">total_users <span class="comment"># 943</span></span><br></pre></td></tr></table></figure>

<p>查看不重复的电影总量（同上）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">total_moves&#x3D;rating_rdd.map(lambda x:x[1]).distinct().count()</span><br><span class="line">total_moves # 1682</span><br></pre></td></tr></table></figure>

<h5 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h5><p>大致处理流程：读取文件=&gt;user_rdd=&gt;raw_rating_rdd=&gt;rating_rdd，这里rating_rdd的格式就是ALS训练数据的格式Rating(user,product,rating)，然后再用ALS.train，训练结束后，就会创建模型对象MatrixFactorizationModel</p>
<p><strong>这里简单介绍ALS算法</strong>：Alternating Least Squares matrix factorization，其实就是（交替）最小二乘法，这里为何使用ALS？因为它同时考虑了User和Item两个方面，即即可基于用户进行推荐又可基于物品，所以适合推荐型的场景，模型一般如下：<br><img src="https://img-blog.csdnimg.cn/20200109205253156.png" alt="Am×n=Um×k×Vk×n"><br>原始协同矩阵是一个<code>m*n</code>的矩阵，是由m<em>k和k</em>n两个矩阵相乘得到的，其中k&lt;&lt;m,n，U表示用户矩阵，V表示商品矩阵，k为U、V矩阵的的秩。学过线性代数应该知道<code>A*B=C</code>，两个矩阵相乘的结果，这就是所谓协同矩阵。<br><img src="https://img-blog.csdnimg.cn/20200109204624664.png" alt="在这里插入图片描述"><br>协同推荐就等同于<code>C=A*B</code>矩阵分解，矩阵分解（协同推荐矩阵是一个稀疏矩阵，因为不是所有的用户都对产品评分）最终又可以转换成了一个优化问题。将用户u对商品V的评分矩阵分解为两个矩阵：一个是用户对商品隐含特征的偏好矩阵，另一个是商品所包含的隐含特征的矩阵。在这个矩阵分解的训练过程中，评分缺失项得到了填充，那么这个填充的项就可以根据用户ID进行推荐。<br>更详细内容可以参考这两篇文章：<a target="_blank" rel="noopener" href="https://blog.csdn.net/YMPzUELX3AIAp7Q/article/details/85241209">文章1</a>、<a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiguage119/p/10813393.html">文章2</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.recommendation <span class="keyword">import</span> ALS</span><br><span class="line"><span class="comment"># 注意ALS算法是基于矩阵运算，因此需要环境安装numpy库</span></span><br></pre></td></tr></table></figure>

<p><code>ALS.train(ratings,rank,iterations=5,lambda_=0.01)</code><br>ratings:训练数据集合，就是上面提到的Rating(user,product,rating)，也即是rating_rdd这个经过预处理的数据集</p>
<p>一句完成训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model=ALS.train(rating_rdd,<span class="number">10</span>,<span class="number">10</span>,<span class="number">0.01</span>)</span><br><span class="line">model<span class="comment"># &lt;pyspark.mllib.recommendation.MatrixFactorizationModel at 0x7f3159bc8048&gt;</span></span><br></pre></td></tr></table></figure>

<p>该模型对象有几个属性：<br>model.rank # 10 分解为稀疏矩阵的秩<br>userFeatures 为分解后的用户矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.userFeatures().take(<span class="number">2</span>)</span><br><span class="line">输出：</span><br><span class="line">[(<span class="number">1</span>,</span><br><span class="line">  array(<span class="string">&#x27;d&#x27;</span>, [-<span class="number">0.7229161262512207</span>, <span class="number">0.036963045597076416</span>, <span class="number">0.23517486453056335</span>, -<span class="number">0.18118669092655182</span>, -<span class="number">1.4776617288589478</span>, -<span class="number">1.0425325632095337</span>, <span class="number">0.3823653757572174</span>, -<span class="number">0.3569445312023163</span>, -<span class="number">0.2874303162097931</span>, <span class="number">0.0020452593453228474</span>])),</span><br><span class="line"> (<span class="number">2</span>,</span><br><span class="line">  array(<span class="string">&#x27;d&#x27;</span>, [-<span class="number">0.3199065327644348</span>, <span class="number">0.41293472051620483</span>, <span class="number">0.12430011481046677</span>, -<span class="number">0.42582616209983826</span>, -<span class="number">0.4546814560890198</span>, -<span class="number">1.496929407119751</span>, <span class="number">0.6246935725212097</span>, <span class="number">0.49794384837150574</span>, -<span class="number">0.3813674747943878</span>, <span class="number">0.7599969506263733</span>]))]</span><br></pre></td></tr></table></figure>

<p>productFeatures为分解后的电影（产品）矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.productFeatures().take(<span class="number">2</span>)</span><br><span class="line">输出：</span><br><span class="line">[(<span class="number">1</span>,</span><br><span class="line">  array(<span class="string">&#x27;d&#x27;</span>, [-<span class="number">0.9663546681404114</span>, <span class="number">0.0724567249417305</span>, <span class="number">0.22562265396118164</span>, -<span class="number">0.14772379398345947</span>, -<span class="number">1.3601692914962769</span>, -<span class="number">1.1434344053268433</span>, <span class="number">1.0299423933029175</span>, -<span class="number">0.17817920446395874</span>, -<span class="number">1.0483288764953613</span>, <span class="number">0.4326847195625305</span>])),</span><br><span class="line"> (<span class="number">2</span>,</span><br><span class="line">  array(<span class="string">&#x27;d&#x27;</span>, [-<span class="number">0.701686441898346</span>, -<span class="number">0.44971194863319397</span>, <span class="number">0.36079081892967224</span>, -<span class="number">0.1727607101202011</span>, -<span class="number">0.4821830689907074</span>, -<span class="number">1.1037342548370361</span>, <span class="number">0.8413264155387878</span>, -<span class="number">0.08249323815107346</span>, -<span class="number">1.0539320707321167</span>, <span class="number">0.6040329337120056</span>]))]</span><br></pre></td></tr></table></figure>

<h5 id="调用已训练的模型"><a href="#调用已训练的模型" class="headerlink" title="调用已训练的模型"></a>调用已训练的模型</h5><p>model已经封装好几个常用的方法，api使用简便</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Signature: model.recommendProducts(user, num)</span><br><span class="line">Docstring:</span><br><span class="line">Recommends the top &quot;num&quot; number of products for a given user and</span><br><span class="line">returns a list of Rating objects sorted by the predicted rating in</span><br><span class="line">descending order.</span><br></pre></td></tr></table></figure>

<p>例如给用户199推荐前5部电影</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.recommendProducts(<span class="number">199</span>,<span class="number">5</span>)</span><br><span class="line">[Rating(user=<span class="number">199</span>, product=<span class="number">854</span>, rating=<span class="number">10.774026140227157</span>),</span><br><span class="line"> Rating(user=<span class="number">199</span>, product=<span class="number">962</span>, rating=<span class="number">9.30074590770409</span>),</span><br><span class="line"> Rating(user=<span class="number">199</span>, product=<span class="number">1176</span>, rating=<span class="number">8.813180359193545</span>),</span><br><span class="line"> Rating(user=<span class="number">199</span>, product=<span class="number">1280</span>, rating=<span class="number">8.11317788460314</span>),</span><br><span class="line"> Rating(user=<span class="number">199</span>, product=<span class="number">718</span>, rating=<span class="number">7.8722593701756995</span>)]</span><br></pre></td></tr></table></figure>

<p>这个结果表示，rating值越大，越排在越前面，代表更为优先推荐，首先推荐给用户199的为854这部电影<br>根据用户ID:199和电影ID:854，查询预测评分:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.predict(<span class="number">199</span>,<span class="number">854</span>) <span class="comment"># 10.774026140227157</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>使用用得更多的场合是：将某部电影推荐给感兴趣的用户，可通过model.recommendUsers得出这些用户，例如，将电影ID为154，推荐给前10个用户</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model.recommendUsers(<span class="number">154</span>,<span class="number">10</span>)</span><br><span class="line">输出：</span><br><span class="line">[Rating(user=<span class="number">133</span>, product=<span class="number">154</span>, rating=<span class="number">6.346890714591231</span>),</span><br><span class="line"> Rating(user=<span class="number">866</span>, product=<span class="number">154</span>, rating=<span class="number">6.10978058348641</span>),</span><br><span class="line"> Rating(user=<span class="number">50</span>, product=<span class="number">154</span>, rating=<span class="number">6.018355541192427</span>),</span><br><span class="line"> Rating(user=<span class="number">783</span>, product=<span class="number">154</span>, rating=<span class="number">5.991043569104054</span>),</span><br><span class="line"> Rating(user=<span class="number">310</span>, product=<span class="number">154</span>, rating=<span class="number">5.658875199814674</span>),</span><br><span class="line"> Rating(user=<span class="number">809</span>, product=<span class="number">154</span>, rating=<span class="number">5.636975519395109</span>),</span><br><span class="line"> Rating(user=<span class="number">78</span>, product=<span class="number">154</span>, rating=<span class="number">5.4898250475467725</span>),</span><br><span class="line"> Rating(user=<span class="number">762</span>, product=<span class="number">154</span>, rating=<span class="number">5.47223950904501</span>),</span><br><span class="line"> Rating(user=<span class="number">273</span>, product=<span class="number">154</span>, rating=<span class="number">5.318862413529849</span>),</span><br><span class="line"> Rating(user=<span class="number">264</span>, product=<span class="number">154</span>, rating=<span class="number">5.295430734770273</span>)]</span><br></pre></td></tr></table></figure>

<p>可以快速得出对电影ID为154最感兴趣的前10个用户，不过在推荐的信息里面，看不到电影名称，还需关联电影名的数据，从而形成完整的推荐信息。</p>
<p>加载电影详情数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">move_info_rdd=sc.textFile(<span class="string">&quot;file:///opt/ml-100k/u.item&quot;</span>)</span><br><span class="line">move_info_rdd.take(<span class="number">3</span>)</span><br><span class="line">输出：</span><br><span class="line">[<span class="string">&#x27;1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>查看u.item电影详情表的字段说明，总共有19个字段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">u.item     -- Information about the items (movies); this <span class="keyword">is</span> a tab separated</span><br><span class="line">              <span class="built_in">list</span> of</span><br><span class="line">              movie <span class="built_in">id</span> | movie title | release date | video release date |</span><br><span class="line">              IMDb URL | unknown | Action | Adventure | Animation |</span><br><span class="line">              Children<span class="string">&#x27;s | Comedy | Crime | Documentary | Drama | Fantasy |</span></span><br><span class="line"><span class="string">              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |</span></span><br><span class="line"><span class="string">              Thriller | War | Western |</span></span><br></pre></td></tr></table></figure>

<p>作为测试，无需使用全部字段，只需挑出感兴趣的字段即可：电影id，电影名，url</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">move_splited_rdd=move_info_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line:line.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取3个字段，将转为map类型，name:电影名，url：电影ur </span></span><br><span class="line">func=<span class="keyword">lambda</span> a_list:(<span class="built_in">int</span>(a_list[<span class="number">0</span>]),<span class="string">&#x27;name:%s,url:%s&#x27;</span>%(a_list[<span class="number">1</span>],a_list[<span class="number">4</span>]))</span><br><span class="line">move_map_info_rdd=move_splited_rdd.<span class="built_in">map</span>(func).collectAsMap() <span class="comment">#move_map_info_rdd 已经是字典类</span></span><br><span class="line">print(move_map_info_rdd)</span><br><span class="line"><span class="comment"># python字典类型的电影信息</span></span><br><span class="line">&#123;<span class="number">1</span>: <span class="string">&#x27;name:Toy Story (1995) url:http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)&#x27;</span>,</span><br><span class="line"> <span class="number">2</span>: <span class="string">&#x27;name:GoldenEye (1995) url:http://us.imdb.com/M/title-exact?GoldenEye%20(1995)&#x27;</span>,</span><br><span class="line"> ......</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>move_map_info_rdd的key就是电影ID，因此只需要关联model.recommendUsers(154,10)输出的<code>Rating(user=133, product=154, rating=6.346890714591231),</code> product id，即可输出完整的推荐信息如下：<br>给用户id为199的用户推荐3部电影</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result=model.recommendProducts(<span class="number">199</span>,<span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> result:</span><br><span class="line">    print(<span class="string">f&#x27;user:<span class="subst">&#123;r.user&#125;</span>,moveid:<span class="subst">&#123;r.product&#125;</span>,move_info:<span class="subst">&#123;move_map_info_rdd[r.product]&#125;</span>,rating:<span class="subst">&#123;r.rating&#125;</span>&#x27;</span>)</span><br><span class="line">  </span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">user:199,moveid:854,move_info:name:Bad Taste (1987) url:http://us.imdb.com/M/title-exact?Bad%20Taste%20(1987),rating:10.774026140227157</span><br><span class="line"></span><br><span class="line">user:199,moveid:962,move_info:name:Ruby in Paradise (1993) url:http://us.imdb.com/M/title-exact?Ruby%20in%20Paradise%20(1993),rating:9.30074590770409</span><br><span class="line"></span><br><span class="line">user:199,moveid:1176,move_info:name:Welcome To Sarajevo (1997) url:http://us.imdb.com/M/title-exact?Welcome+To+Sarajevo+(1997),rating:8.813180359193545</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>将model持久化到本地后，再封装为完整的逻辑，方便重新使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model.save(sc,<span class="string">&#x27;/opt/ml-100k/asl_model&#x27;</span>) <span class="comment"># sc为spark程序开头的spark context</span></span><br><span class="line"><span class="comment"># 若再次存储再会提示出错，所以一般是这么用：</span></span><br><span class="line"><span class="keyword">try</span>：</span><br><span class="line">    model.save(sc,path)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<p>model以一个目录的形式保存，而且还保存了user和product的数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@nn ml-100k]# tree asl_model/</span><br><span class="line">asl_model/</span><br><span class="line">├── data</span><br><span class="line">│   ├── product</span><br><span class="line">│   │   ├── part-00000-bf34d65a-81e8-4124-a254-6e6044b8da2d-c000.snappy.parquet</span><br><span class="line">│   │   └── _SUCCESS</span><br><span class="line">│   └── user</span><br><span class="line">│       ├── part-00000-3953175d-e560-42a5-8de3-fcc86a4b625c-c000.snappy.parquet</span><br><span class="line">│       └── _SUCCESS</span><br><span class="line">└── metadata</span><br><span class="line">    ├── part-00000</span><br><span class="line">    └── _SUCCESS</span><br></pre></td></tr></table></figure>

<p>如何加载已训练好的本地模型？使用load方法即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load(sc,<span class="string">&#x27;/opt/ml-100k/asl_model&#x27;</span>) <span class="comment"># path为</span></span><br></pre></td></tr></table></figure>
<h5 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h5><p>将以上的处理流程封装类，便于调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyspark</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext <span class="keyword">as</span> sc</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.mllib.recommendation <span class="keyword">import</span> ALS</span><br><span class="line"><span class="keyword">import</span> os,datetime</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MoveRecommend</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,model_path,user_path,move_path,app_name=<span class="string">&quot;move_recommend&quot;</span>,master=<span class="string">&quot;local[*]&quot;</span></span>):</span></span><br><span class="line">        self.app_name=app_name</span><br><span class="line">        self.master=master</span><br><span class="line">        self.sc=self.create_spark_context()</span><br><span class="line">        self.train_rank=<span class="number">10</span> <span class="comment"># 稀疏矩阵分解的秩</span></span><br><span class="line">        self.train_iter=<span class="number">10</span> <span class="comment"># 迭代次数</span></span><br><span class="line">        self.train_lambda=<span class="number">0.01</span> <span class="comment"># 正则化参数(惩罚因子)        </span></span><br><span class="line">        self.user_path=user_path </span><br><span class="line">        self.move_path=move_path</span><br><span class="line">        self.model_path=model_path</span><br><span class="line">        self.model=self.get_model()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_time</span>():</span></span><br><span class="line">        d=datetime.datetime.now()</span><br><span class="line">        <span class="keyword">return</span> d.strftime(<span class="string">&#x27;%M:%S&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_spark_context</span>(<span class="params">self</span>):</span></span><br><span class="line">        conf=SparkConf().setAppName(self.app_name).setMaster(self.master)</span><br><span class="line">        spark_context=sc.getOrCreate(conf)    </span><br><span class="line">        <span class="keyword">return</span> spark_context</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_model</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;如果给定的目录没有model，则重新训练model，如果已有model，则直接加载使用&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(self.model_path):</span><br><span class="line">            print(<span class="string">f&#x27;model not found,start traing at <span class="subst">&#123;self.get_time()&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> self.train_and_save()</span><br><span class="line">        <span class="keyword">return</span> model.load(self.sc,self.model_path)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_and_save</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;只用训练集，训练model并持久化到本地目录&quot;&quot;&quot;</span></span><br><span class="line">        user_rdd=self.sc.textFile(<span class="string">&quot;file://&quot;</span>+self.user_path)</span><br><span class="line">        raw_rating_rdd=user_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line:line.split(<span class="string">&#x27;\t&#x27;</span>)[:<span class="number">3</span>]) <span class="comment"># 每行分割后为一个包含4个元素的列表，取前3项即可</span></span><br><span class="line">        rating_rdd=raw_rating_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(x[<span class="number">0</span>],x[<span class="number">1</span>],x[<span class="number">2</span>]))<span class="comment"># x[0],x[1],x[2]对应用户id，电影id，评分</span></span><br><span class="line">        model=ALS.train(rating_rdd,self.train_rank,self.train_iter,self.train_lambda)</span><br><span class="line">        model.save(self.sc,self.model_path)</span><br><span class="line">        print(<span class="string">f&#x27;model training done at <span class="subst">&#123;self.get_time()&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> model </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_move_dict</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;返回一个字典列表，每个字典存放3个电影详情字段&quot;&quot;&quot;</span>        </span><br><span class="line">        move_info_rdd=self.sc.textFile(<span class="string">&quot;file://&quot;</span>+self.move_path)</span><br><span class="line">        move_splited_rdd=move_info_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line:line.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">        <span class="comment"># 提取3个字段，将转为map类型，name:电影名，url：电影ur </span></span><br><span class="line">        func=<span class="keyword">lambda</span> a_list:(<span class="built_in">int</span>(a_list[<span class="number">0</span>]),<span class="string">&#x27;name:%s,url:%s&#x27;</span>%(a_list[<span class="number">1</span>],a_list[<span class="number">4</span>]))</span><br><span class="line">        move_map_info_rdd=move_splited_rdd.<span class="built_in">map</span>(func).collectAsMap() <span class="comment">#move_map_info_rdd 已经是字典类 </span></span><br><span class="line">        <span class="keyword">return</span> move_map_info_rdd</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">recommend_product_by_userid</span>(<span class="params">self,user_id,num=<span class="number">5</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;根据给定用户id，向其推荐top N部电影&quot;&quot;&quot;</span>                </span><br><span class="line">        result= self.model.recommendProducts(user_id,num)</span><br><span class="line">        move_dict=self.get_move_dict()</span><br><span class="line">        <span class="keyword">return</span> [(r.user,r.product,move_dict[r.product],r.rating) <span class="keyword">for</span> r <span class="keyword">in</span> result]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">recommend_user_by_moveid</span>(<span class="params">self,move_id,num=<span class="number">5</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;根据给定电影ID，推荐对该电影感兴趣的top N 个用户&quot;&quot;&quot;</span>     </span><br><span class="line">        result=self.model.recommendUsers(move_id,num)</span><br><span class="line">        move_dict=self.get_move_dict()</span><br><span class="line">        <span class="keyword">return</span> [(r.user,r.product,move_dict[r.product],r.rating) <span class="keyword">for</span> r <span class="keyword">in</span> result]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>调用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">m=MoveRecom(model_path=<span class="string">&#x27;/opt/ml-100k/costom_model&#x27;</span>,user_path=<span class="string">&#x27;/opt/ml-100k/u.data&#x27;</span>,move_path=<span class="string">&#x27;/opt/ml-100k/u.item&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>输出训练时间：<br>model not found,start traing at 26:45<br>model training done at 27:06</p>
<h5 id="项目难点说明"><a href="#项目难点说明" class="headerlink" title="项目难点说明"></a>项目难点说明</h5><p>&#8195;&#8195;上面的例子只是给出demo流程，而且数据已准备，但如果针对实际项目，则需要你处理以下两个主要难点：<br>（1） 训练数据的获取、整理和加工，并将这一流程自动化。<br>（2）模型的训练，以及根据新数据重新训练模型，以保证模型推荐效果最优，并将这一流程自动化。<br>&#8195;&#8195;至于其他工作，例如web 层面的开发，以及Apps或者说底层数据的存储，对于全栈开发者来说，并无大碍，只是需要耗费更多精力而已。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>&#8195;&#8195;本文给出了较为入门的基于PySpark实现的推荐类的业务流程，该逻辑其实是离线的模式：训练数据已经加工好，模型训练也没有进行深度调优。事实上，如果将其作为一个生产可用项目来实施，需将大数据生态圈相关技术栈以及web 开发进行整合，此类项目的架构设计一般有下面三部分：</p>
<ul>
<li>需推荐的业务数据（包括训练集和测试集）收集、计算、存储：大数据生态圈相关技术栈实现</li>
<li>模型训练方面：离线存储PySpark计算后生成的训练模型，而且需要定时训练和更新该模型文件，以便保持最优模型。</li>
<li>以web api的方式提供推荐数据：为BI或者其他应用以get、post的方式提供推荐数据，例如post一个用户ID，返回相应的推荐条目</li>
</ul>
<p>以下简要说明两种基本架构图：<br><strong>第一种：适合数据量不大，几个节点组成的小型“大数据”服务</strong><br><img src="https://img-blog.csdnimg.cn/20200111095444386.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">&#8195;&#8195;这种架构较为简单，数据源本身已经存储在各个业务的原有数据库中或者日志文件，开发者无需借助hadoop存储组件，自行实现数据源抽取模块，接着只需PySpark读取这些数据并训练成模型文件即可，模型文件管理可以通过定时训练更新，最后通过web API的形式为上层应用提供推荐或者匹配记录。<br>需要注意的是：构建web API方式这里用了Python栈，当然可用Java栈或者Go栈</p>
<p><strong>第二种：适合数据量大的中大型大数据服务</strong><br><img src="https://img-blog.csdnimg.cn/20200111100116354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">&#8195;&#8195;此类架构适合那些几十GB到几百GB级别甚至是TB级别的分布式大数据节点集群，此类场景需引入hadoop相关生态圈的技术栈，用于处理大量属鸡的存储和计算：Flume、Kafka、HBase、Hive，在计算层提供分布式的Spark组件支撑离线模型计算。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/Spark/" rel="tag"># Spark</a>
              <a href="/blog/tags/PySpark%E6%8E%A8%E8%8D%90/" rel="tag"># PySpark推荐</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2020/01/04/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90asyncio%E4%B8%8E%E5%8D%8F%E7%A8%8B/" rel="prev" title="深入解析asyncio与协程">
      <i class="fa fa-chevron-left"></i> 深入解析asyncio与协程
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2020/01/14/Spark%20DataFrame%E3%80%81Spark%20SQL%E3%80%81Spark%20Streaming%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/" rel="next" title="Spark DataFrame、Spark SQL、Spark Streaming入门教程">
      Spark DataFrame、Spark SQL、Spark Streaming入门教程 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81PySpark%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">1、PySpark简介</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81Pyspark%E6%8E%A5%E5%8F%A3%E7%94%A8%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">2、Pyspark接口用法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E6%BA%90"><span class="nav-number">2.1.</span> <span class="nav-text">读取数据源</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%AE%97%E5%AD%90"><span class="nav-number">2.2.</span> <span class="nav-text">常用算子</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84wordcount%E7%A4%BA%E4%BE%8B"><span class="nav-number">2.3.</span> <span class="nav-text">完整的wordcount示例</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81%E5%9F%BA%E4%BA%8EPySpark%E5%92%8CALS%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E6%B5%81%E7%A8%8B"><span class="nav-number">3.</span> <span class="nav-text">3、基于PySpark和ALS的电影推荐流程</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E8%83%8C%E6%99%AF"><span class="nav-number">3.1.</span> <span class="nav-text">数据集背景</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE"><span class="nav-number">3.2.</span> <span class="nav-text">读取用户数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.3.</span> <span class="nav-text">训练模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%B0%83%E7%94%A8%E5%B7%B2%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.4.</span> <span class="nav-text">调用已训练的模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="nav-number">3.5.</span> <span class="nav-text">完整代码</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%A1%B9%E7%9B%AE%E9%9A%BE%E7%82%B9%E8%AF%B4%E6%98%8E"><span class="nav-number">3.6.</span> <span class="nav-text">项目难点说明</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-number">4.</span> <span class="nav-text">小结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt=""
      src="https://www.linuxprobe.com/wp-content/uploads/2018/06/QQ%E5%9B%BE%E7%89%8720180625205006.png">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">一个非常专注技术总结与分享的博客</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">48</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">48</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yield-bytes</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">577k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">8:44</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/pjax/pjax.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/pisces.js"></script>


<script src="/blog/js/next-boot.js"></script>

<script src="/blog/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/blog/js/local-search.js"></script>













    <div id="pjax">
  

  

  

    </div>
</body>
</html>
