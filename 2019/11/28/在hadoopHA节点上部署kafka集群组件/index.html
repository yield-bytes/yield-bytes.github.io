<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yield-bytes.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","Pisces | Gemini":240,"width":300,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="&amp;#8195;&amp;#8195;在前面的文章中《在hadoopHA节点上部署flume高可用组件 》已经介绍了flume实时收集acces.log，同时给出flume是如何实现数据流向的高可用环境测试。在后面的文章中会给出实时大数据项目的开发，实时数据源由flume sink到kafka的topic里，而不是前面提到的hdfs，目的是利用kafka强大的分布式消息组件用于分发来自flume的实时数据流">
<meta property="og:type" content="article">
<meta property="og:title" content="在HadoopHA节点上部署Kafka集群组件">
<meta property="og:url" content="https://yield-bytes.github.io/2019/11/28/%E5%9C%A8HadoopHA%E8%8A%82%E7%82%B9%E4%B8%8A%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6/index.html">
<meta property="og:site_name" content="yield-bytes">
<meta property="og:description" content="&amp;#8195;&amp;#8195;在前面的文章中《在hadoopHA节点上部署flume高可用组件 》已经介绍了flume实时收集acces.log，同时给出flume是如何实现数据流向的高可用环境测试。在后面的文章中会给出实时大数据项目的开发，实时数据源由flume sink到kafka的topic里，而不是前面提到的hdfs，目的是利用kafka强大的分布式消息组件用于分发来自flume的实时数据流">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191124162957995.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2019-11-28T14:02:03.000Z">
<meta property="article:modified_time" content="2020-11-22T10:56:02.470Z">
<meta property="article:tag" content="kafka集群">
<meta property="article:tag" content="hadoop HA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20191124162957995.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">

<link rel="canonical" href="https://yield-bytes.github.io/2019/11/28/%E5%9C%A8HadoopHA%E8%8A%82%E7%82%B9%E4%B8%8A%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>在HadoopHA节点上部署Kafka集群组件 | yield-bytes</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="yield-bytes" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">yield-bytes</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">沉淀、分享与无限进步</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th-large fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://gitee.com/yield-bytes" class="github-corner" title="Follow me on Gitee" aria-label="Follow me on Gitee" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yield-bytes.github.io/2019/11/28/%E5%9C%A8HadoopHA%E8%8A%82%E7%82%B9%E4%B8%8A%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://www.linuxprobe.com/wp-content/uploads/2018/06/QQ%E5%9B%BE%E7%89%8720180625205006.png">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="一个聪明的、友好的且专注于高水平技术总结的个人博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yield-bytes">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          在HadoopHA节点上部署Kafka集群组件
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-28 22:02:03" itemprop="dateCreated datePublished" datetime="2019-11-28T22:02:03+08:00">2019-11-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-11-22 18:56:02" itemprop="dateModified" datetime="2020-11-22T18:56:02+08:00">2020-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>&#8195;&#8195;在前面的文章中<a target="_blank" rel="noopener" href="https://blog.csdn.net/pysense/article/details/103214906">《在hadoopHA节点上部署flume高可用组件 》</a>已经介绍了flume实时收集acces.log，同时给出flume是如何实现数据流向的高可用环境测试。在后面的文章中会给出实时大数据项目的开发，实时数据源由flume sink到kafka的topic里，而不是前面提到的hdfs，目的是利用kafka强大的分布式消息组件用于分发来自flume的实时数据流。<br>kafka集群在Hadoop实时大数据项目的位置，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20191124162957995.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">   </p>
<a id="more"></a>
<h4 id="1、Kafka的基本介绍"><a href="#1、Kafka的基本介绍" class="headerlink" title="1、Kafka的基本介绍"></a>1、Kafka的基本介绍</h4><h5 id="1-1-什么是kafka"><a href="#1-1-什么是kafka" class="headerlink" title="1.1 什么是kafka"></a>1.1 什么是kafka</h5><p>Kafka 是一种分布式的，基于发布/订阅的消息系统（redis也可以实现该功能），主要设计目标如下：<br>以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。<br>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。<br>支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。<br>同时支持离线数据处理和实时数据处理。<br>Scale out：支持在线水平扩展。</p>
<h5 id="1-2-kafka-应用场景"><a href="#1-2-kafka-应用场景" class="headerlink" title="1.2 kafka 应用场景"></a>1.2 kafka 应用场景</h5><ul>
<li>日志收集：可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer。不过在本文中，flume用于收集数据日志，kafka组件用于接受来自flume的event</li>
<li>流式处理：spark streaming，在上面的架构图也可以清楚看到kafka组件的下游为spark streaming，它消费来自kafka topic的实时数据消息。</li>
<li>消息系统：解耦生产者和消费者、缓存消息等。</li>
<li>用户活动跟踪：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后消费者通过订阅这些topic来做实时的监控分析，亦可保存到hbase、mangodb等数据库。</li>
<li>运营指标：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，</li>
<li>生产各种操作的集中反馈，比如报警和报告。<br>可以看出kafka在大数据实时处理以及互联网产品方面应用最为突出。</li>
</ul>
<h5 id="1-3-kafka相关术语"><a href="#1-3-kafka相关术语" class="headerlink" title="1.3 kafka相关术语"></a>1.3 kafka相关术语</h5><ul>
<li>producer : 生产者，生产message发送到topic，例如flume sink就是生产者</li>
<li>consumer : 消费者，订阅topic并消费message, consumer作为一个线程来消费，例如实时处理的spark streaming。</li>
<li><p>Broker：Kafka节点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群，在大数据项目中，直接利用已有的hadoop节点服务器配置成kafka集群。整个 Kafka 集群架构会有一个 zookeeper集群，通过 zookeeper 管理集群配置，选举 kafka Leader，以及在 Consumer Group 发生变化时进行 Rebalance。</p>
</li>
<li><p>topic：一类消息，消息存放的目录即主题，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发</p>
</li>
<li>massage： Kafka中最基本的传递对象。</li>
<li>partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的segment以及index：partition在物理上已一个文件夹的形式存在，由多个segment文件组成和多个index文件，它们是很对出现，每个Segment存着message信息，每个index存放着message的offset</li>
<li>replica：partition 的副本，保障 partition 的高可用。个人建议写成replica partition—副本分区</li>
<li>leader：这里的leader要理解为某个partition 作为主分区，也即称为leader partition，要注意该partition所在的服务器不能称为leader，否认会被误认为是kafka集群的master服务器（Kafka把master服务器称为controller）。 producer 和 consumer 只跟 leader petition交互。</li>
<li>replicas：leader 角色的partition加上replica角色的partition，一起成为replicas，也就是该topic总共有多少个副本数，副本数包含一个主分区副本和其余的副本分区。</li>
<li>controller：为了避免更leader这个词混淆，开发者将kafka 集群中的其中一台服务器称为controller，用于对每个topic的partition leader选举以及实现对partition的failover。</li>
<li>consumer Group：消费者组，一个Consumer Group包含多个consumer</li>
<li>offset：偏移量，理解为消息partition中的索引</li>
</ul>
<h4 id="2、kafka-单点部署与测试"><a href="#2、kafka-单点部署与测试" class="headerlink" title="2、kafka 单点部署与测试"></a>2、kafka 单点部署与测试</h4><h5 id="2-1-配置文件"><a href="#2-1-配置文件" class="headerlink" title="2.1 配置文件"></a>2.1 配置文件</h5><p>目前官方kafka最新稳定版本为2.3.1<br>按官方建议以下建议，项目用到scala2.1.3，kafka用了官方的建议版本2.1.2<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">We build for multiple versions of Scala. This only matters if you are using Scala and you want a version built for the same Scala version you use. Otherwise any version should work (2.12 is recommended). </span><br></pre></td></tr></table></figure><br>kafka组件同样被放置在/opt目录下，该目录放置所有Hadoop及其组件，便于统一管理<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@nn opt]# ls</span><br><span class="line">flume-1.9.0   hbase-2.1.7   kafka-2.12      scala-2.13.1             </span><br><span class="line">flume_log     hive-3.1.2    mariadb-10.4.8  spark-2.4.4-bin-hadoop2.7  zookeeper-3.4.14</span><br><span class="line">hadoop-3.1.2  jdk1.8.0_161    xcall.sh          </span><br></pre></td></tr></table></figure></p>
<p>配置server.properties。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@nn config]# vi server.properties </span><br><span class="line">[root@nn config]# pwd</span><br><span class="line">/opt/kafka-2.12/config</span><br><span class="line"><span class="meta">#</span><span class="bash"> The id of the broker. This must be <span class="built_in">set</span> to a unique <span class="built_in">integer</span> <span class="keyword">for</span> each broker.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果是kafka集群，需配置全局id</span></span><br><span class="line">broker.id=10</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Socket Server Settings #############################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以不设置，kafka自动获取hostname</span></span><br><span class="line">listeners=PLAINTEXT://nn:9092</span><br><span class="line">advertised.listeners=PLAINTEXT://nn:9092</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Log Basics #############################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 最终存放消息的路径,建议放在kafka组件目录下，方便管理</span></span><br><span class="line">log.dirs=/opt/kafka-2.12/kafka-logs</span><br><span class="line">num.partitions=3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Zookeeper #############################</span></span></span><br><span class="line">zookeeper.connect=nn:2181,dn1:2181,dn2:2181/kafka-zk</span><br><span class="line"><span class="meta">#</span><span class="bash"> Timeout <span class="keyword">in</span> ms <span class="keyword">for</span> connecting to zookeeper</span></span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br></pre></td></tr></table></figure><br>已更新配置：<del>zookeeper.connect=nn:2181,dn1:2181,dn2:2181</del><br>考虑到后面项目中，对kafka在zk上方便更为管理，用了新的配置：zookeeper.connect=nn:2181,dn1:2181,dn2:2181/kafka-zk<br>因为kafka默认在zk的根路径下创建多个节点路径，当需要去zk查看kafka相关的元数据时显得有点混乱，因此这里要求kafka将它要创建的所有znode都统一放在/kafka-zk这个路径下，方便集中查看和管理kafka的元数据，如下所示：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 0]  ls /kafka-zk</span><br><span class="line">[cluster, controller_epoch, controller, brokers, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure><br>本文后面内容所有kafka命令中，若有<code>--zookeeper nn:2181</code> 这样启动参数，都需要改为<code>--zookeeper nn:2181/kafka-zk</code></p>
<h5 id="2-2-启动kafka进程"><a href="#2-2-启动kafka进程" class="headerlink" title="2.2 启动kafka进程"></a>2.2 启动kafka进程</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-2.12]# bin/kafka-server-start.sh config/server.properties </span><br></pre></td></tr></table></figure>
<p>启动后提示内存不足<br>“There is insufficient memory ”<br>因为kafka的启动脚本为最大堆申请1G内存，由于使用虚拟机跑项目，资源有限，将 kafka-server-start.sh的export KAFKA_HEAP_OPTS=”-Xmx1G -Xms1G”修改为export KAFKA_HEAP_OPTS=”-Xmx256M -Xms128M”，最大堆空间为256M，初始堆空间为128M。<br>使用后台进程方式启动kafka服务<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-2.12]# bin/kafka-server-start.sh -daemon config/server.properties </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过jps也可以看到kafka进程</span></span><br><span class="line">[root@nn kafka-2.12]# jps</span><br><span class="line">4609 QuorumPeerMain</span><br><span class="line">14436 JournalNode</span><br><span class="line">2454 HMaster</span><br><span class="line">2552 Jps</span><br><span class="line">14185 DataNode</span><br><span class="line">15017 NodeManager</span><br><span class="line">2365 Kafka</span><br><span class="line">13983 NameNode</span><br><span class="line">14879 ResourceManager</span><br></pre></td></tr></table></figure></p>
<h5 id="2-3-测试topic"><a href="#2-3-测试topic" class="headerlink" title="2.3 测试topic"></a>2.3 测试topic</h5><p>创建无备份的topic,名称为hadoop，分区数1<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-2.12]#bin/kafka-topics.sh --create --zookeeper nn:2181 --replication-factor 1  --partitions 1 --topic hadoop</span><br><span class="line">Created topic hadoop.</span><br></pre></td></tr></table></figure><br>查看新建的topic<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@nn bin]# kafka-topics.sh --list --zookeeper nn:2181</span><br><span class="line">hadoop</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看kafka在zookeeper上创建的topic znode上可以看到 hadoop这个topic</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 2] ls /brokers</span><br><span class="line">[ids, topics, seqid]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 3] ls /brokers/topics</span><br><span class="line">[hadoop]</span><br></pre></td></tr></table></figure><br>启动producer进程，这是一个console，可以命令式发送message<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-2.12]# bin/kafka-console-producer.sh --broker-list nn:9092 --topic hadoop</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">hello kafka</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">spark</span></span><br></pre></td></tr></table></figure></p>
<p>新打开一个shell用于启动consumer进程，订阅hadoop这个topic，该进程会持续监听9092端口，一旦上面producer的console写入信息，这边consumer就会立刻打印同样信息。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-2.12]# bin/kafka-console-consumer.sh --bootstrap-server nn:9092 --topic hadoop</span><br><span class="line">hello kafka</span><br><span class="line">spark</span><br></pre></td></tr></table></figure></p>
<p>查看hadoop这个topic的所在的物理文件<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 这里的hadoop-0就是hadoop topic的parition</span></span><br><span class="line">[root@nn hadoop-0]# pwd</span><br><span class="line">/opt/kafka-2.12/kafka-logs/hadoop-0</span><br><span class="line"></span><br><span class="line">[root@nn hadoop-0]# ls</span><br><span class="line">00000000000000000000.index  00000000000000000000.log  00000000000000000000.timeindex  leader-epoch-checkpoint</span><br></pre></td></tr></table></figure><br>有index、log文件，新版本的kafka还多了timeindex时间索引。至此完成kafka单节点的配置和测试。</p>
<h4 id="3、kafka集群部署与测试"><a href="#3、kafka集群部署与测试" class="headerlink" title="3、kafka集群部署与测试"></a>3、kafka集群部署与测试</h4><h5 id="3-1-配置server-properties"><a href="#3-1-配置server-properties" class="headerlink" title="3.1 配置server.properties"></a>3.1 配置server.properties</h5><p>kafka集群部署要求所在节点上已经运行zookeeper集群。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@nn config]# vi server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 每个节点id需唯一nn设10，dn1设11，dn2设12</span></span><br><span class="line">broker.id=10</span><br><span class="line">ip和端口这里可以不配置，kafka自动读取，也方便把整个kafka目录分发到其他节点上</span><br><span class="line"><span class="meta">#</span><span class="bash">listeners=PLAINTEXT://:9092</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 存放的日志，kafka自动创建</span></span><br><span class="line">log.dirs=/opt/kafka-2.12/kafka-logs</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置zk集群</span></span><br><span class="line">zookeeper.connect=nn:2181,dn1:2181,dn2:2181</span><br></pre></td></tr></table></figure><br>其他属性项基本是调优项目，这里不再一一给出，后面用单独一篇文章给出讨论。<br>将kafka-2.12目录拷贝到dn1和dn2节点上，修改对应的broker.id即可</p>
<h5 id="3-2-集群测试"><a href="#3-2-集群测试" class="headerlink" title="3.2 集群测试"></a>3.2 集群测试</h5><p>分布在三个节点上启动kafka服务<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-2.12]# bin/kafka-server-start.sh -daemon config/server.properties </span><br><span class="line">[root@dn1 kafka-2.12]# bin/kafka-server-start.sh -daemon config/server.properties </span><br><span class="line">[root@dn2 kafka-2.12]# bin/kafka-server-start.sh -daemon config/server.properties </span><br><span class="line"><span class="meta">#</span><span class="bash"> jps可以看到每个节点上都已经有kafka进程</span></span><br><span class="line">[root@nn opt]# sh xcall.sh jps |grep ka</span><br><span class="line">10569 Kafka</span><br><span class="line">12836 Kafka</span><br><span class="line">28243 Kafka</span><br></pre></td></tr></table></figure></p>
<p>创建一个新的topic：sparkapp，3份拷贝，3分区<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-2.12]# bin/kafka-topics.sh --create --zookeeper nn:2181,dn1:2181,dn2:2181 --replication-factor 3 --partitions 3 --topic sparkapp</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看sparkapp主分区及其副本分区的情况</span></span><br><span class="line">[root@nn kafka-2.12]# bin/kafka-topics.sh --describe --zookeeper nn:2181 --topic sparkapp</span><br><span class="line">Topic:sparkapp  PartitionCount:3        ReplicationFactor:3     Configs:</span><br><span class="line">        Topic: sparkapp Partition: 0    Leader: 10      Replicas: 10,11,12      Isr: 10,11,12</span><br><span class="line">        Topic: sparkapp Partition: 1    Leader: 11      Replicas: 11,12,10      Isr: 11,12,10</span><br><span class="line">        Topic: sparkapp Partition: 2    Leader: 12      Replicas: 12,10,11      Isr: 12,10,11</span><br></pre></td></tr></table></figure><br>该命令其实就是读取/brokers/topics/sparkapp/partitions/**/state 所有分区的state节点值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 9] get  &#x2F;brokers&#x2F;topics&#x2F;sparkapp&#x2F;partitions&#x2F;0&#x2F;state</span><br><span class="line">&#123;&quot;controller_epoch&quot;:22,&quot;leader&quot;:10,&quot;version&quot;:1,&quot;leader_epoch&quot;:0,&quot;isr&quot;:[10,11,12]&#125;</span><br></pre></td></tr></table></figure></p>
<p>在nn节点启动producer进程，连接broker分别为nn自己、dn1节点和dn2节点，都能正常连接，同理，dn1、dn2的producer进程使用dn1、dn2、nn节点都能正常连接<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-2.12]# bin/kafka-console-producer.sh --broker-list nn:9092 --topic sparkapp</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">sparkapp</span></span><br><span class="line"></span><br><span class="line">[root@nn kafka-2.12]# bin/kafka-console-producer.sh --broker-list dn1:9092 --topic sparkapp</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">sparkapp</span></span><br><span class="line"></span><br><span class="line">[root@nn kafka-2.12]# bin/kafka-console-producer.sh --broker-list dn2:9092 --topic sparkapp</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">sparkapp</span></span><br></pre></td></tr></table></figure></p>
<p>在nn节点启动producer进程，然后在dn1节点、dn2节点以及nn新shell分别启动consumer，看看一个producer生产msg，其他三个节点能否同时收到<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@dn1 kafka-2.12]# bin/kafka-console-consumer.sh --bootstrap-server nn:9092 --topic sparkapp</span><br><span class="line">[root@dn2 kafka-2.12]# bin/kafka-console-consumer.sh --bootstrap-server nn:9092 --topic sparkapp</span><br><span class="line">[root@nn kafka-2.12]# bin/kafka-console-consumer.sh --bootstrap-server nn:9092 --topic sparkapp</span><br></pre></td></tr></table></figure></p>
<p>查看kafka-cluster这个topic的partition在物理文件上的分布<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-logs]# ls sparkapp-</span><br><span class="line">sparkapp-0/ sparkapp-1/ sparkapp-2/ </span><br><span class="line">[root@nn kafka-logs]# ls sparkapp-0/</span><br><span class="line">00000000000000000000.index  00000000000000000000.timeindex</span><br><span class="line">00000000000000000000.log    leader-epoch-checkpoint</span><br></pre></td></tr></table></figure><br>可以看到三个分区对于三个文件目录，每个目录有索引文件和数据文件</p>
<h5 id="3-3-在zk上查看集群情况"><a href="#3-3-在zk上查看集群情况" class="headerlink" title="3.3 在zk上查看集群情况"></a>3.3 在zk上查看集群情况</h5><p>kafka在zk上的数据存储结构：<br>brokers列表：ls /brokers/ids<br>某个broker信息：get /brokers/ids/10<br>topic信息：get /brokers/topics/sparkapp<br>partition信息：get /brokers/topics/sparkapp/partitions/0/state<br>controller中心节点变更次数：get /controller_epoch<br>conrtoller信息：get /controller<br>[zk: localhost:2181(CONNECTED) 2] get /controller<br>{“version”:1,”brokerid”:10,”timestamp”:”<em>*</em>“}，可以看到当前kafka集群的controller节点为nn服务器brokerid为10.<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 集群的brokers信息在/brokers持久节点下，ids节点用于存放上线的brokers id号，topics：集群上所有的topces都放在在节点下</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 20] ls /brokers</span><br><span class="line">[ids, topics, seqid]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> brokers在持久ids节点下注册临时节点，节点名称就是broker自己的id号，这里说明为何在server.properties里面的broker.id要设为唯一，因为利用zookeeper的临时节点以及保证节点命名唯一。</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 19] ls /brokers/ids</span><br><span class="line">[10,11,12]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取其中一个broker id节点的信息，例如dn2这个broker</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 24] get /brokers/ids/12</span><br><span class="line">&#123;&quot;listener_security_protocol_map&quot;:&#123;&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;&#125;,&quot;endpoints&quot;:[&quot;PLAINTEXT://dn2:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;dn2&quot;,&quot;timestamp&quot;:&quot;*****&quot;,&quot;port&quot;:9092,&quot;version&quot;:4&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看sparkapp这个topics的分区数量</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 8] ls /brokers/topics/sparkapp/partitions</span><br><span class="line">[0, 1, 2]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看当前kafka集群的leader状态，通过在topic的分区的state节点可以看到当前leader是节点dn1，对应的broker id为1</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 36] get /brokers/topics/sparkapp/partitions/1/state</span><br><span class="line">&#123;&quot;controller_epoch&quot;:6,&quot;leader&quot;:10,&quot;version&quot;:1,&quot;leader_epoch&quot;:2,&quot;isr&quot;:[11,12,10]&#125;</span><br></pre></td></tr></table></figure><br>至此，完成Kafka的集群配置和测试</p>
<h4 id="4、-小结"><a href="#4、-小结" class="headerlink" title="4、 小结"></a>4、 小结</h4><p>为hadoop环境配置kafka组件的过程相对简单，鉴于Kafka这个中间件具有非常不错应用价值，本blog继续用1到2篇文章深入探讨有关Kafka核心内容。此外还用另外一篇文章用于给出flume和kafka两者的整合——<a target="_blank" rel="noopener" href="https://blog.csdn.net/pysense/article/details/103335495">《flume集群高可用连接kafka集群》</a>。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/kafka%E9%9B%86%E7%BE%A4/" rel="tag"># kafka集群</a>
              <a href="/tags/hadoop-HA/" rel="tag"># hadoop HA</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/11/24/%E5%9C%A8hadoopHA%E8%8A%82%E7%82%B9%E4%B8%8A%E9%83%A8%E7%BD%B2flume%E9%AB%98%E5%8F%AF%E7%94%A8%E7%BB%84%E4%BB%B6/" rel="prev" title="在hadoopHA节点上部署flume高可用组件">
      <i class="fa fa-chevron-left"></i> 在hadoopHA节点上部署flume高可用组件
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/12/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kafka/" rel="next" title="深入理解Kafka">
      深入理解Kafka <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81Kafka%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">1、Kafka的基本介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-1-%E4%BB%80%E4%B9%88%E6%98%AFkafka"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 什么是kafka</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2-kafka-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 kafka 应用场景</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-3-kafka%E7%9B%B8%E5%85%B3%E6%9C%AF%E8%AF%AD"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 kafka相关术语</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81kafka-%E5%8D%95%E7%82%B9%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="nav-number">2.</span> <span class="nav-text">2、kafka 单点部署与测试</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 配置文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-%E5%90%AF%E5%8A%A8kafka%E8%BF%9B%E7%A8%8B"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 启动kafka进程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-%E6%B5%8B%E8%AF%95topic"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 测试topic</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81kafka%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="nav-number">3.</span> <span class="nav-text">3、kafka集群部署与测试</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-%E9%85%8D%E7%BD%AEserver-properties"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 配置server.properties</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-%E9%9B%86%E7%BE%A4%E6%B5%8B%E8%AF%95"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 集群测试</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-3-%E5%9C%A8zk%E4%B8%8A%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E6%83%85%E5%86%B5"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 在zk上查看集群情况</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81-%E5%B0%8F%E7%BB%93"><span class="nav-number">4.</span> <span class="nav-text">4、 小结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt=""
      src="https://www.linuxprobe.com/wp-content/uploads/2018/06/QQ%E5%9B%BE%E7%89%8720180625205006.png">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">一个聪明的、友好的且专注于高水平技术总结的个人博客</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">74</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yield-bytes</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">1.1m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">17:22</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  

  

    </div>
</body>
</html>
