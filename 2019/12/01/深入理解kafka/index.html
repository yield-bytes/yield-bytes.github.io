<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yield-bytes.gitee.io","root":"/blog/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","Pisces | Gemini":240,"width":300,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="&amp;#8195;&amp;#8195;在前面的文章《在hadoopHA节点上部署kafka集群组件》，介绍大数据实时分析平台生态圈组件——kafka，前向用于连接flume，后向连接spark streaming。在研究Kafka过程中，发现该中间件的设计很巧妙，因此专设一篇文章用于深入理解Kafka核心知识。Kafka已经纳入个人目前最欣赏的中间件list：redis，zookeeper，kafka 1、">
<meta property="og:type" content="article">
<meta property="og:title" content="深入理解Kafka">
<meta property="og:url" content="https://yield-bytes.gitee.io/blog/2019/12/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kafka/index.html">
<meta property="og:site_name" content="yield-bytes">
<meta property="og:description" content="&amp;#8195;&amp;#8195;在前面的文章《在hadoopHA节点上部署kafka集群组件》，介绍大数据实时分析平台生态圈组件——kafka，前向用于连接flume，后向连接spark streaming。在研究Kafka过程中，发现该中间件的设计很巧妙，因此专设一篇文章用于深入理解Kafka核心知识。Kafka已经纳入个人目前最欣赏的中间件list：redis，zookeeper，kafka 1、">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191127231934698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191130122756221.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191130120633422.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191130215819665.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191201103918787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191201104854685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2019120111063329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191201111807824.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191201114330792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191201120617771.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2019-12-01T04:16:41.000Z">
<meta property="article:modified_time" content="2020-11-22T10:55:35.661Z">
<meta property="article:tag" content="Kafka原理">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20191127231934698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">

<link rel="canonical" href="https://yield-bytes.gitee.io/blog/2019/12/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kafka/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>深入理解Kafka | yield-bytes</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/blog/atom.xml" title="yield-bytes" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">yield-bytes</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">分享与沉淀</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-th-large fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://gitee.com/yield-bytes" class="github-corner" title="Follow me on Gitee" aria-label="Follow me on Gitee" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yield-bytes.gitee.io/blog/2019/12/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://www.linuxprobe.com/wp-content/uploads/2018/06/QQ%E5%9B%BE%E7%89%8720180625205006.png">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="一个非常专注技术总结与分享的博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yield-bytes">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深入理解Kafka
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-01 12:16:41" itemprop="dateCreated datePublished" datetime="2019-12-01T12:16:41+08:00">2019-12-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-11-22 18:55:35" itemprop="dateModified" datetime="2020-11-22T18:55:35+08:00">2020-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>12k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>11 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>&#8195;&#8195;在前面的文章<a target="_blank" rel="noopener" href="https://blog.csdn.net/pysense/article/details/103225653">《在hadoopHA节点上部署kafka集群组件》</a>，介绍大数据实时分析平台生态圈组件——kafka，前向用于连接flume，后向连接spark streaming。在研究Kafka过程中，发现该中间件的设计很巧妙，因此专设一篇文章用于深入理解Kafka核心知识。Kafka已经纳入个人目前最欣赏的中间件list：redis，zookeeper，kafka</p>
<h4 id="1、kafka集群架构图"><a href="#1、kafka集群架构图" class="headerlink" title="1、kafka集群架构图"></a>1、kafka集群架构图</h4><p>以下为kafka集群一种经典的架构图，该图以《在hadoopHA节点上部署kafka集群组件》文章的kafka集群以及sparkapp topic作为示例绘成，本文的内容将以该图为标准作为说明。<br><img src="https://img-blog.csdnimg.cn/20191127231934698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="kafka集群架构图">图1 kafka集群架构图</p>
<a id="more"></a>

<h4 id="2、kafka-高性能读写的设计"><a href="#2、kafka-高性能读写的设计" class="headerlink" title="2、kafka 高性能读写的设计"></a>2、kafka 高性能读写的设计</h4><h5 id="2-1、利用read-ahead-和-write-behind提升写性能"><a href="#2-1、利用read-ahead-和-write-behind提升写性能" class="headerlink" title="2.1、利用read-ahead 和 write-behind提升写性能"></a>2.1、利用read-ahead 和 write-behind提升写性能</h5><p>&#8195;&#8195;kafka底层设计高度依赖现代磁盘优化技术和文件系统的优化技术。在kafka官方文档的：<a target="_blank" rel="noopener" href="http://kafka.apache.org/documentation/#design">don’t fear the filesystem</a>章节说明了kafka是如何利用磁盘已有的高性能读写技术：read-ahead 和 write-behind 实现日志在磁盘山高性能顺序写。<br>&#8195;&#8195;read-ahead 是以大的 data block 为单位预先读取数据。write-behind（后写） 是将多个小型的逻辑写合并成一次大型的物理磁盘写入，producer向kafka写入消息日志时，因为消息是一条一条的过来，而且消息本身payload很小，如果每条消息进来立刻执行写入磁盘，显然IO非常高，因此需要将进来的消息先缓存，然后到一定数量或者到一定容量时再触发写入磁盘，kafka用了pagecache实现write-behind而不是通过内存。<br>&#8195;&#8195;官方举例说明用廉价的RAID-5模式sata硬盘可以去到600MB/秒，但随机写入的性能仅约为100k/秒，相差6000倍以上。</p>
<h5 id="2-2、使用pagecache缓存程序数据提升读写性能"><a href="#2-2、使用pagecache缓存程序数据提升读写性能" class="headerlink" title="2.2、使用pagecache缓存程序数据提升读写性能"></a>2.2、使用pagecache缓存程序数据提升读写性能</h5><p>&#8195;&#8195;同样，在kafka官方文档的：<a target="_blank" rel="noopener" href="http://kafka.apache.org/documentation/#design">don’t fear the filesystem</a>章节还提到另外一个技术：pagecache。kafka利用了现代操作系统主动将所有空闲内存用作磁盘caching这一机制（代价是在内存回收时性能会有所降低），再次提升基于filesystem的读写性能的效果。<br>&#8195;&#8195;kafka 跑在 jvm之上，那么jvm一定会有复杂的GC情况：</p>
<ul>
<li>对象的内存开销非常高，通常是所存储的数据的两倍(甚至更多)。</li>
<li>随着堆中数据的增加，Java 的垃圾回收变得越来越复杂和缓慢。</li>
</ul>
<p>&#8195;&#8195;受这些因素影响， 维护in-memory cache就会显得很复杂，而kafka通过文件系统方式和 pagecache 读写消息反而显得更有优势（避免复杂低效率的GC），通过自动访问所有空闲内存将可用缓存的容量至少翻倍，并且通过存储紧凑的字节结构而不是独立的对象，有望将缓存容量再翻一番，例如32GB内存的服务器，它的 pagecache缓存容量可以达到28-30GB，并且不会产生额外的 GC 负担。kafka自己也说还有重要一点：简化核心代码。<br>为何这么设计？<br>&#8195;&#8195;kafka自己这么解释：因为相比于维护尽可能多的 in-memory cache，并且在空间不足的时候匆忙将消息数据 flush 到文件系统的，kafka写过程把这个过程倒过来：所有消息数据一开始就被写入（write-behind）到文件系统的持久化日志中，而不用在in-memory cache 空间不足的时候 flush 到磁盘。实际上，是先把数据被转移到了内核的 pagecache 中。<br>&#8195;&#8195;这里可以联想到Hbase的MemStore设计：MemStore基于in-memory cache，MemStore 在内存中存在，保存修改key-value数据，当MemStore的大小达到一个阀值（默认64MB）时，MemStore里面的数据会被flush到Hfile文件上，也就是flush到磁盘上。</p>
<p>==为何page cache 会加速读过程？==<br>linux的文件cache分为两层，一个是page cache，另一个是buffer cache；每一个page cache包含若干个buffer cache，结构图如下图所示：<br><img src="https://img-blog.csdnimg.cn/20191130122756221.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>page cache：文件系统层级的缓存，从磁盘里读取数据缓存到page cache（属于内核空间，而不是应用用户的空间），这样应用读磁盘数据会被加速，例如使用find等命令查找文件时，第一次会慢很多，第二次查找相同文件时会瞬间读取到。如果page cache的数据被修改过后，也即脏数据，等到写入磁盘时机到来时，会把数据转移到buffer cache 而不是直接写入到磁盘。<br>buffer cache：磁盘等块设备的缓冲。<br>大致流程：<br><img src="https://img-blog.csdnimg.cn/20191130120633422.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">page cache其优化读的工作过程如下：<br>A、文件的第一次读请求<br>系统读入所请求的page页并读入紧随其后的的少数几个页面，这种读取方式称为同步预读。<br>B、文件的第二次读请求:<br>如果page页不在第一次的cache中，说明不是顺序读，所以又会重新继续第一次那种同步预读过程。</p>
<p>==如果page页面在cache中，说明是顺序读，Linux会将预读group扩大一倍==，继续把不在首次cache中的文件数据读进来，此为异步预读。kafka之所以设计按顺序读写，完全就是按照底层page cahe的这种预读机制来设计，所以在文件系统底层就已经有不错的性能了。</p>
<h5 id="2-3-通过sendfile（零拷贝机制）提高消费者端的读吞吐量"><a href="#2-3-通过sendfile（零拷贝机制）提高消费者端的读吞吐量" class="headerlink" title="2.3 通过sendfile（零拷贝机制）提高消费者端的读吞吐量"></a>2.3 通过sendfile（零拷贝机制）提高消费者端的读吞吐量</h5><p>&#8195;&#8195;在kafka官方文档的Efficiency章节解释了kafka通过使用sendfile （零拷贝技术）继续提高消费者端的读性能。<br>&#8195;&#8195;前面2.1和2.2解释了kafka里利用相关底层机制，解决了磁盘访问模式不佳的情况。接下来，还需要解决以下两个影响kafka性能的情况：<br>too many small I/O operations, and excessive byte copying<br>（大量的小型 I/O 操作以及过多的字节拷贝 ）</p>
<ul>
<li><p>A、 The small I/O problem happens both between the client and the server and in the server’s own persistent operations.<br>（大量小型的 I/O 操作表现在client和broker之间以及broker服务端自身持久化操作中）<br>解决方式：kafka用一个称为 “消息块” 的抽象基础上，合理将消息分组。 这使得网络请求将多个消息打包成一组，而不是每次发送一条消息，从而使整组消息分担网络中往返的开销。consumer 每次获取多个大型有序的消息块，并由服务端依次将消息块一次加载到它的日志中。<br>这个简单的优化对速度有着数量级的提升。批处理允许更大的网络数据包，更大的顺序读写磁盘操作，连续的内存块等等</p>
</li>
<li><p>B、excessive byte copying<br>另一个低效率的操作是字节拷贝，在消息量少时，这不是什么问题，但是在高负载的情况下，影响就不容忽视。为了避免这种情况，kafka在producer、broker 和 consumer 都是用相同标准化的二进制消息格式，这样数据块不用修改就能在他们之间传递。<br>broker 维护的消息日志本身就是一个文件目录，每个segment文件都由一系列以相同格式消息组成，保持这种通用格式将非常有利于消息日志文件的网络传输的效率。 现代的unix 操作系统提供了一个高度优化的编码方式，用于将数据从 pagecache 转移到 socket 网络连接中，减少内核拷贝次数；在 Linux 中系统调用<a target="_blank" rel="noopener" href="http://man7.org/linux/man-pages/man2/sendfile.2.html"> sendfile </a>方式做到这一点。 </p>
</li>
</ul>
<p>先看看数据从磁盘文件到套接字的拷贝过程：<br><code>File.read(fileDesc, buf, len);</code><br><code>Socket.send(socket, buf, len);</code><br>以上两个操作是java语义的读取文件和socket发送数据包，一共有两次拷贝？当然不是的：<br>1） 操作系统从磁盘读取数据到内核空间的 page cache<br>2）应用程序从内核空间 page cache读取数据到用户空间的缓冲区（应用程序的地址空间）<br>3）应用程序将数据(用户空间的缓冲区)写回内核空间到套接字缓冲区(内核空间)<br>4）操作系统将数据从套接字缓冲区(内核空间)复制到通过网络发送的 NIC 缓冲区<br>以上过程有四次 copy 操作和两次系统调用，如果数据传输吞吐量大时，对Kafka来说低效率，如何减少拷贝次数？<br>使用 内核提供的sendfile 方法，使用零拷贝的应用程序要求内核直接将数据从磁盘文件拷贝到套接字，而无需通过应用程序。零拷贝不仅大大地提高了应用程序的性能，而且还减少了内核与用户模式间的上下文切换。例如一个 topic 被多消费者消费时，使用上面zero-copy（零拷贝）优化，消息在使用时只会被复制到pagecache 中一次，节省了每次拷贝到用户空间内存中，再从用户空间进行读取的消耗。这使得消息能够以接近服务器网卡Gb级别的网速来进行消费。</p>
<blockquote>
<p>在应用程序和网络之间提供更快的数据传输方法，从而可以有效地降低通信延迟，提高网络吞吐率。零拷贝技术是实现主机或者路由器等设备高速网络接口的主要技术之一。举例来说，一个 1 GHz 的处理器可以对 1Gbit/s 的网络链接进行传统的数据拷贝操作，但是如果是 10 Gbit/s 的网络，那么对于相同的处理器来说，零拷贝技术就变得非常重要了。</p>
</blockquote>
<p>page cache 和 sendfile 的组合使用意味着，在一个kafka集群中，大多数 consumer 消费时，==将看不到磁盘上的读取活动，因为数据将完全由缓存提供==。<br>有关zero-copy以及Linux IO详细内容，推荐IBM Developer中国区四篇高质量文章：<br><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/linux/l-cn-directio/index.html?mhsrc=ibmsearch_a&mhq=%E9%9B%B6%E6%8B%B7%E8%B4%9D">《Linux 中直接 I/O 机制的介绍》</a><br><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/index.html?mhsrc=ibmsearch_a&mhq=%E9%9B%B6%E6%8B%B7%E8%B4%9D">《Linux 中的零拷贝技术，第 1 部分》</a><br><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/index.html?mhsrc=ibmsearch_a&mhq=%E9%9B%B6%E6%8B%B7%E8%B4%9D">《Linux 中的零拷贝技术，第 2 部分》</a><br><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/java/j-zerocopy/index.html?mhsrc=ibmsearch_a&mhq=%E9%9B%B6%E6%8B%B7%E8%B4%9D">《通过零拷贝实现有效数据传输》</a>，这篇文章翻译了IBM Developer官方英文原文：<a target="_blank" rel="noopener" href="https://developer.ibm.com/articles/j-zerocopy/">《Efficient data transfer through zero copy》</a><br>阅读这几篇文章可以说收益匪浅，不仅深度理解了kafka使用filesystem作为消息队列的底层文件IO，而且也有利于理解任何基于文件系统上的中间件的部分实现机制。</p>
<h4 id="3、kafka的repilcas副本机制"><a href="#3、kafka的repilcas副本机制" class="headerlink" title="3、kafka的repilcas副本机制"></a>3、kafka的repilcas副本机制</h4><h5 id="3-1-主分区的副本"><a href="#3-1-主分区的副本" class="headerlink" title="3.1 主分区的副本"></a>3.1 主分区的副本</h5><p>&#8195;&#8195;Kafka 允许 topic 的 partition 拥有若干副本，也就是说每个partition都有一个 leader 和零或多个 followers，例如图1 kafka集群架构图中，sparkapp这个topic，在broker1有主分区（leader）partition-0，在broker-1和broker-2有followers副本分区（replica）partition-0。  总的副本数是包含 leader 分区的总和。 所有的读写操作都由 leader 处理，各分区的 leader 均 匀的分布在brokers 中，一个topic在当前broker只能有一个leader主分区。followers节点就像普通的 consumer 那样从 leader 节点那里拉取消息并保存在自己的日志文件中。</p>
<h5 id="3-2-leade如何管理follower节点"><a href="#3-2-leade如何管理follower节点" class="headerlink" title="3.2 leade如何管理follower节点"></a>3.2 leade如何管理follower节点</h5><p>&#8195;&#8195;Kafka 判断节点是否存活有两种方式。</p>
<ul>
<li>首先follower所在的broker服务器在线，Zookeeper 通过心跳机制检查每个broker的连接，对应的znode路径/brokers/ids。</li>
<li>要求follower角色的同步进程 ，它必须能及时的同步 leader 的写操作，并且延时不能太多。 </li>
</ul>
<p>&#8195;&#8195;kafka认为满足这两个条件的节点处于 “in sync” 状态， Leader会追踪所有 “in sync” 的节点。如果有节点挂掉了, 或是写超时, 或是心跳超时, leader 就会把它从同步副本集合ISR中移除。这个ISR列表在zookeeper可以看到，a set of In-Sync Replicas，简称：ISR：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 36] get &#x2F;brokers&#x2F;topics&#x2F;sparkapp&#x2F;partitions&#x2F;1&#x2F;state</span><br><span class="line">&#123;&quot;controller_epoch&quot;:6,&quot;leader&quot;:10,&quot;version&quot;:1,&quot;leader_epoch&quot;:2,&quot;isr&quot;:[11,12,10]&#125;</span><br></pre></td></tr></table></figure>
<p>&#8195;&#8195;以上说明：sparkapp的partition-1这个主分区在brokerid为10的服务器上，其他follower的brokerid分别为11和12。<br>可配置在ISR移除follower的触发条件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 如果leader发现follower超过10秒没有向它发起同步请求，那么leader会认为follower无法正常同步主分区日志，就把它从ISR集合中中移除。</span><br><span class="line"> rerplica.lag.time.max.ms&#x3D;10000 # 默认值</span><br><span class="line"> # 相差1000条就从ISR集合移除该follower</span><br><span class="line"> rerplica.lag.max.messages&#x3D;1000# 默认值</span><br></pre></td></tr></table></figure>

<h5 id="3-3-Replica如何均匀分布到整个kafka集群"><a href="#3-3-Replica如何均匀分布到整个kafka集群" class="headerlink" title="3.3 Replica如何均匀分布到整个kafka集群"></a>3.3 Replica如何均匀分布到整个kafka集群</h5><p>&#8195;&#8195;为了更好的做负载均衡以及HA，Kafka尽量降所有的replicas均匀分配到整个集群上。为了更直观partition的副本是如何被分布到不同节点上，这里以一个小例子为例：创建一个fooTopic（可以先把它理解为消息队列queue，类似RabbitMQ的队列）且有五个分区，每个分区有三个副本replica，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@nn kafka-2.12]# bin&#x2F;kafka-topics.sh --create --zookeeper nn:2181 --replication-factor 3 --partitions 5 --topic fooTopic</span><br><span class="line">[root@dn1 kafka-2.12]#  bin&#x2F;kafka-topics.sh --describe --zookeeper nn:2181 --topic fooTopic</span><br><span class="line">Topic:fooTopic  PartitionCount:5        ReplicationFactor:3     Configs:</span><br><span class="line">        Topic: fooTopic Partition: 0    Leader: 11      Replicas: 11,10,12      Isr: 11,10,12</span><br><span class="line">        Topic: fooTopic Partition: 1    Leader: 12      Replicas: 12,11,10      Isr: 12,11,10</span><br><span class="line">        Topic: fooTopic Partition: 2    Leader: 10      Replicas: 10,12,11      Isr: 10,12,11</span><br><span class="line">        Topic: fooTopic Partition: 3    Leader: 11      Replicas: 11,12,10      Isr: 11,12,10</span><br><span class="line">        Topic: fooTopic Partition: 4    Leader: 12      Replicas: 12,10,11      Isr: 12,10,11</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Kafka分配资源跟很多中间件一样：通过取余实现，具体的规则如下：<br> 1）序号为i的Partition分配到第（i mod n）个Broker上，n为集群的broker总数<br> 2）序列号为i的Partition的第j个Replica分配到第（(i + j) mod n）个Broker上</p>
<p>以上述fooTopic为例，给出其分布过程：首先查看broker ids的列表为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] ls &#x2F;brokers&#x2F;ids</span><br><span class="line">[11, 12, 10]</span><br></pre></td></tr></table></figure>
<p>[11, 12, 10]列表的项的索引从0开始，因为kafka是用Scala语言开发，Scala获取zk这个ids值后，肯定是转为Scala数组类型，它的索引从0开始。当然也适用replicas数组（列表）。（这里为何不是[10, 11, 12]？因为本次获取结果是最新的集群选举结果数组）<br>假设a=[11, 12, 10]那么a[0]=11,a=[1]=12,a[2]=10</p>
<ul>
<li><p>按规则1）对于partition的序号i，它会分配到第（i mod n）个broker上：<br>那么对于partition0，0 mod 3=0，所以该在a[0]=11这个broker上，<br>同理有：<br>partition1，1 mod 3=1，所以该在a[1]=12这个broker上<br>partition2，2 mod 3=2，所以该在a[2]=10这个broker上<br>partition3，3 mod 3=0，所以该在a[0]=11这个broker上<br>partition4，4 mod 3=1，所以该在a[1]=12这个broker上</p>
</li>
<li><p>按规则 2）序列号为i的Partition的第j个Replica分配到第（(i + j) mod n）个Broker上<br>那么对于序列号为4的partition和序列号为0的replica，（4+0）mod 3=1，所以该在a[1]=12这个broker上，那么这个就是主leader分区，符合规则1partition4在12这个broker的计算结果。<br>那么对于序列号为4的partition和序列号为1的replica，（4+1）mod 3=2，所以该在a[2]=10这个broker上，<br>那么对于序列号为4的partition和序列号为2的replica，（4+2）mod 3=0，所以该在a[0]=11这个broker上<br>也就说partition4的replicas为[12,10,11]</p>
</li>
</ul>
<h4 id="4、Kafka消息的ack机制"><a href="#4、Kafka消息的ack机制" class="headerlink" title="4、Kafka消息的ack机制"></a>4、Kafka消息的ack机制</h4><p>&#8195;&#8195;这里是指producer向broker写消息的确认机制，这直接影响到Kafka集群的吞吐量和消息可靠性。而吞吐量和可靠性是矛盾的，两者不可兼得，只能平衡。<br>&#8195;&#8195;在第3章节提到leader和follower节点日志同步的内容，kafka动态维护了一个同步状态的副本的集合，在这个集合中的节点都是和leader保持高度一致的，任何一条消息只有被这个集合中的每个节点读取并追加到日志中，才会向外部通知说“这个消息已经committed。<br>&#8195;&#8195;也就是说只有当消息被ISR上所有的followers加入到日志中时，才算是“committed”，只有committed的消息才会发送给consumer，这样就不用担心一旦leader down掉了消息会丢失。这一环节就是决定了消息队列吞吐量和可靠性的环节。消息从leader复制到follower，可通过producer是否等待消息被提交的通知(ack)来区分同步复制和异步复制。<br>ack有3个可选值，分别是1，0，-1，可通过server.properties进行配置：<br>request.required.asks=0<br>==ack=0==:相当于异步的，producer给broker发送一次就不再发送了，不管本条消息是否在leader和follower都写入成功。可靠性低，吞吐量当然高。<br>==ack=1==：producer等待leader这个主分区成功写入了消息，producer才会认为消息发送成功，这是默认值，显然是吞吐量与可靠性的一个折中方案<br>==ack=-1==：当所有的follower都同步消息成功后，leader再向producer发送ack，producer才认为此消息发送成功，显然牺牲了吞吐量，因为如果leader有多个followers，同步需要一定时间，producer当然要等待一段时间后，再能继续向leader发送新消息。</p>
<p>当然ack=1的情况下，消息也可能会丢失，这是因为：<br>producer只要收到分区leader成功写入的通知就会认为消息发送成功了，但是也有这样的情况：leader成功写入后，还没来得及把数据同步到follower节点超时等，这时候消息会丢失。</p>
<p>清楚了kafka的ack机制后，来看看ack=-1的同步复制过程：<br>1）producer首先取zookeeper找到指定topic的主分区leader，向leader发送消息<br>2）leader收到消息写入到本地segment文件<br>3）所有follower从leader pull消息并写入自己segment文件<br>4）所有follower向leader发送ack消息<br>5）leader收到所有follower的ack消息<br>6）leader向producer发送ack<br>7）producer收到成功写入的响应</p>
<h4 id="5、kafka-消息索引机制"><a href="#5、kafka-消息索引机制" class="headerlink" title="5、kafka 消息索引机制"></a>5、kafka 消息索引机制</h4><p>&#8195;&#8195;前面的四节内容更多是kafka集群本身的一些机制，其实对于consumer侧，当consumer去broker pull一条的消息时，broker是如何快速找出相应的消息呢？<br>&#8195;&#8195;在前面部署Kafka集群已经知道每个partition都是一个文件目录，每个目录下有成index文件和log文件，它们是成对出现，后缀 “.index” 和 “.log” 分表表示 segment 索引文件和数据文件（存放消息的地方），segment的大小以及相关配置可在server.properties进行设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#segment文件的大小，默认为 1G</span><br><span class="line">log.segment.bytes&#x3D;1024*1024*1024</span><br><span class="line">#滚动生成新的segment文件的最大时长</span><br><span class="line">log.roll.hours&#x3D;24*7</span><br><span class="line">#segment文件保留的最大时长，超过7天将被删除</span><br><span class="line">log.retention.hours&#x3D;24*7</span><br></pre></td></tr></table></figure>
<p>&#8195;&#8195;Segment 是 Kafka 存储消息的最小单位，Segment 文件命名规则：对于某个partition，例如partition0，全局的第一个 Segment 从 0 开始，后续每个 Segment 文件名为上一个 Segment 文件最后一条消息的 offset 值。数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用 0 填充。如 00000000000000368769.index 和 00000000000000368769.log。<br>对于parition1，它全局的第一个 Segment 也是从 0 开始，切勿认为parition0的最后一个segment的offset会顺延到partition1！<br>以下图为例，分析costumer如何根据offset拿到消息数据：<br>（因为集群测试环境还没有太多segment数据，所以这里参考这篇<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/fX26tCdYSMgwM54_2CpVrw">文章的内容</a>：）<br><img src="https://img-blog.csdnimg.cn/20191130215819665.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">&#8195;&#8195;假设现在研究partition0，在它.index文件中，存储的是key-value格式的值：&lt;n,m&gt;，n代表在.log中按顺序开始第n条消息，m代表该消息的位置偏移m，这里以索引文件中元数据 <code>&lt;3, 497&gt;</code> 为例，表示该368769.log文件中第 3 条Message，该消息所在物理位置为 497。<br>现在consumer要取offset为368773的消息，以下为查找过程：<br>1）在partition0下，有多个segment的index文件，根据二分法，可以快速地位到368772条消息在368769.index上<br>2）在368769.index索引文件，找出&lt;n,m&gt;的具体值，n=368774-368769=4（一般称为base offset），因为索引文件是稀疏结构，4这个值不在索引文件上<br>3）再根据二分法，很快找到3这个base offset&lt;3,497&gt;，因为索引值4没有，只能用不大于4的索引值3。<br>4）再回到368769.log上，从物理位置497开始按顺序查找，当物理位置到达830时，offset为368773的消息被找到。</p>
<p>&#8195;&#8195;从上图可以知道 Index 文件也不是每次递增 1 的，这是因为 Kafka 采取稀疏索引存储的方式，每隔一定字节的数据建立一条索引。它减少了索引文件大小，使得能够把 Index 映射到内存，降低了查询时的磁盘 IO 开销，同时也并没有给查询带来太多的时间消耗。<br>&#8195;&#8195;要满足以上的搜索策略：Kafka为在 Partition 中的每一条 Message 都定义了以下三个属性：</p>
<ul>
<li>Offset：表示 Message 在当前 Partition 中的偏移量，是一个逻辑上的值，唯一确定了在当前Partition 中的一条 Message</li>
<li>MessageSize：表示 Message 内容 Data 的大小。</li>
<li>Data：Message 的具体内容。<br>因此只要消费者只需要订阅的topic后，一旦拿到消息的offset，broker就会按以上检索策略将消息取出。</li>
</ul>
<h4 id="6、consumer-group的工作机制"><a href="#6、consumer-group的工作机制" class="headerlink" title="6、consumer group的工作机制"></a>6、consumer group的工作机制</h4><p>&#8195;&#8195;在图1可看到有多个consumer group，本章节主要探讨为何kafka使用consumer group的设计。<br>&#8195;&#8195;consumer group是kafka实现单播和广播两种消息模型的方式：<br>同一个topic的消息，可以广播给不同的group；<br>同一个topic的消息，每个group里面只能被其中的一个consumer消费。group内的consumer可以使用多线程或多进程来实现，consumer数量建议与partition成整数倍关系，因为kafka设计一个partition只能被group内一个consumer消费，也即是单播模式。</p>
<h5 id="6-1-一个topic为何需要被多个consumer消费？"><a href="#6-1-一个topic为何需要被多个consumer消费？" class="headerlink" title="6.1  一个topic为何需要被多个consumer消费？"></a>6.1  一个topic为何需要被多个consumer消费？</h5><p>&#8195;&#8195;以图1的sparkapp这个topic为例，假设没有consumer group，假设只有一个consumer去消费kafka集群的sparkapp，考虑到consumer只能从leader分区消费，相当于以下架构图：<br><img src="https://img-blog.csdnimg.cn/20191201103918787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">从单个consumer视角观察sparkapp，集群为consumer提供三个分区消费：（leader）partition0、（leader）partition1、（leader）partition2，所以上图简化成下图：</p>
<p><img src="https://img-blog.csdnimg.cn/20191201104854685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">但如果当producer写入消息的速度比consumer读取的速度快呢？结果是：消息堆积越来越严重，对于这种情况，需要增加多个消费者来进行水平扩展消息的读取。<br>可以用实际案例说明：<br>例如这个sparkapp的消息是待发送邮箱的内容和用户邮箱地址，如果仅有一个consumer去读取消息再发邮箱通知用户，那么随消息堆积越来越严重，将会有大量用户不能及时收到邮件通知。<br>解决办法：增加多个consumer，一般是跟leader分区的数目一致，例如本例3个leader分区，对应3个consumer进行消费，每个consumer消费分别对应一个分区进行消费，如下图所示：<br><img src="https://img-blog.csdnimg.cn/2019120111063329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">这就保证了生产的消息能够及时被consumer消费处理掉，表现在实际应用场景的效果：大量用户能够及时收到邮箱通知。<br>==注意：consumer数量建议与partition成整数倍关系，例如上面的1倍关系，因为kafka设计一个partition只能被group内一个consumer消费，也即是单播模式。<br>consumer数量由客户端自己通过多线程方式或者多进程方式实现。==</p>
<h5 id="6-2-同一个partition能否被多个consumer同时消费？"><a href="#6-2-同一个partition能否被多个consumer同时消费？" class="headerlink" title="6.2 同一个partition能否被多个consumer同时消费？"></a>6.2 同一个partition能否被多个consumer同时消费？</h5><p>例如（leader）partition0同时被两个consumer消费，如下所示：<br><img src="https://img-blog.csdnimg.cn/20191201111807824.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">以邮箱通知这个为例子：<br>两个consumer将拿到重复的消息，在用户侧的效果就是：所有用户都会重复收到同一内容邮箱通知，显然不能接受。<br>kafka设计早已考虑到这些情况，所有kafka不允许同一个consumer group中的两个consumer读取同一个partition。</p>
<h5 id="6-3-kafka为何设计多个consumer-group这样的模型？"><a href="#6-3-kafka为何设计多个consumer-group这样的模型？" class="headerlink" title="6.3 kafka为何设计多个consumer group这样的模型？"></a>6.3 kafka为何设计多个consumer group这样的模型？</h5><p>以邮箱通知这个为例子：<br>这个sparkapp的消息是待发送邮箱的内容和用户邮箱地址，现在有两个应用需要拉取sparkapp这个topic的消息，一个是邮箱通知应用A，另外一个是存储邮箱内容和用户邮箱地址的应用B。</p>
<h6 id="6-3-1-无consumer-group，应用A和应用B会出现什么情况？"><a href="#6-3-1-无consumer-group，应用A和应用B会出现什么情况？" class="headerlink" title="6.3.1 无consumer group，应用A和应用B会出现什么情况？"></a>6.3.1 无consumer group，应用A和应用B会出现什么情况？</h6><p><img src="https://img-blog.csdnimg.cn/20191201114330792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">因为kafka设计每个consumer只能消费一个partition，如上图示，<br>==对于应用A，它开了2个线程==，消费(leader)partition0和(leader)partition1，在用户侧的出现情况：有一部分用户根本没收到邮件通知，漏了(leader)partition2这部分的数据。<br>==对于应用B，它只能开一个线程==，也即是一个consumer，而且只能拿到(leader)partition2的消息，最终出现的情况：数据库里面，根本没有存储到一部分用户的邮件记录。显然是漏了(leader)partition0和(leader)partition1的数据。<br>如何解决上述问题？</p>
<h6 id="6-3-2-为应用建立consumer-group，观测应用A和应用B的情况。"><a href="#6-3-2-为应用建立consumer-group，观测应用A和应用B的情况。" class="headerlink" title="6.3.2 为应用建立consumer group，观测应用A和应用B的情况。"></a>6.3.2 为应用建立consumer group，观测应用A和应用B的情况。</h6><p>考虑到两个应用，这里对应两个group，如下图示：<br><img src="https://img-blog.csdnimg.cn/20191201120617771.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">group A 对应应用A，group B 对应应用B<br>kafka限定：<br>group内的consumer只能消费一个分区<br>同一分区（的一条信息）可以被不同group消费，广播模式。<br>从上图的结构可以看出：<br>应用A可以把三个分区的邮箱通知内容都发送到所有用户，不会出现像6.3.1 的情况：遗漏部分数据。<br>应用B可以把三个分区的邮箱通知内容都存储到数据库，不会出现像6.3.1 的情况：遗漏部分数据。<br>这就是kafka的consumer group的设计逻辑。<br>小结：<br>1）如果一个应用需要读取全量消息，那么可为该应用设置一个消费组；<br>如果该应用消费能力不足，那么可以考虑在这个消费组里增加消费者。<br>2） kafka支持写入的一条消息能够被若干个应用读取这条消息。也就是说：<br>每个应用都可以读到全量的消息，通过为每个应用设置自己的消费组。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/Kafka%E5%8E%9F%E7%90%86/" rel="tag"># Kafka原理</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2019/11/28/%E5%9C%A8HadoopHA%E8%8A%82%E7%82%B9%E4%B8%8A%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6/" rel="prev" title="在HadoopHA节点上部署Kafka集群组件">
      <i class="fa fa-chevron-left"></i> 在HadoopHA节点上部署Kafka集群组件
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2019/12/05/flume%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BF%9E%E6%8E%A5kafka%E9%9B%86%E7%BE%A4/" rel="next" title="flume集群高可用连接kafka集群">
      flume集群高可用连接kafka集群 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81kafka%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84%E5%9B%BE"><span class="nav-number">1.</span> <span class="nav-text">1、kafka集群架构图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81kafka-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AF%BB%E5%86%99%E7%9A%84%E8%AE%BE%E8%AE%A1"><span class="nav-number">2.</span> <span class="nav-text">2、kafka 高性能读写的设计</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1%E3%80%81%E5%88%A9%E7%94%A8read-ahead-%E5%92%8C-write-behind%E6%8F%90%E5%8D%87%E5%86%99%E6%80%A7%E8%83%BD"><span class="nav-number">2.1.</span> <span class="nav-text">2.1、利用read-ahead 和 write-behind提升写性能</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2%E3%80%81%E4%BD%BF%E7%94%A8pagecache%E7%BC%93%E5%AD%98%E7%A8%8B%E5%BA%8F%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8D%87%E8%AF%BB%E5%86%99%E6%80%A7%E8%83%BD"><span class="nav-number">2.2.</span> <span class="nav-text">2.2、使用pagecache缓存程序数据提升读写性能</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-%E9%80%9A%E8%BF%87sendfile%EF%BC%88%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%9C%BA%E5%88%B6%EF%BC%89%E6%8F%90%E9%AB%98%E6%B6%88%E8%B4%B9%E8%80%85%E7%AB%AF%E7%9A%84%E8%AF%BB%E5%90%9E%E5%90%90%E9%87%8F"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 通过sendfile（零拷贝机制）提高消费者端的读吞吐量</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81kafka%E7%9A%84repilcas%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6"><span class="nav-number">3.</span> <span class="nav-text">3、kafka的repilcas副本机制</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-%E4%B8%BB%E5%88%86%E5%8C%BA%E7%9A%84%E5%89%AF%E6%9C%AC"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 主分区的副本</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-leade%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86follower%E8%8A%82%E7%82%B9"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 leade如何管理follower节点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-3-Replica%E5%A6%82%E4%BD%95%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83%E5%88%B0%E6%95%B4%E4%B8%AAkafka%E9%9B%86%E7%BE%A4"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 Replica如何均匀分布到整个kafka集群</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81Kafka%E6%B6%88%E6%81%AF%E7%9A%84ack%E6%9C%BA%E5%88%B6"><span class="nav-number">4.</span> <span class="nav-text">4、Kafka消息的ack机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5%E3%80%81kafka-%E6%B6%88%E6%81%AF%E7%B4%A2%E5%BC%95%E6%9C%BA%E5%88%B6"><span class="nav-number">5.</span> <span class="nav-text">5、kafka 消息索引机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6%E3%80%81consumer-group%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">6.</span> <span class="nav-text">6、consumer group的工作机制</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#6-1-%E4%B8%80%E4%B8%AAtopic%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E8%A2%AB%E5%A4%9A%E4%B8%AAconsumer%E6%B6%88%E8%B4%B9%EF%BC%9F"><span class="nav-number">6.1.</span> <span class="nav-text">6.1  一个topic为何需要被多个consumer消费？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-2-%E5%90%8C%E4%B8%80%E4%B8%AApartition%E8%83%BD%E5%90%A6%E8%A2%AB%E5%A4%9A%E4%B8%AAconsumer%E5%90%8C%E6%97%B6%E6%B6%88%E8%B4%B9%EF%BC%9F"><span class="nav-number">6.2.</span> <span class="nav-text">6.2 同一个partition能否被多个consumer同时消费？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-3-kafka%E4%B8%BA%E4%BD%95%E8%AE%BE%E8%AE%A1%E5%A4%9A%E4%B8%AAconsumer-group%E8%BF%99%E6%A0%B7%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="nav-number">6.3.</span> <span class="nav-text">6.3 kafka为何设计多个consumer group这样的模型？</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#6-3-1-%E6%97%A0consumer-group%EF%BC%8C%E5%BA%94%E7%94%A8A%E5%92%8C%E5%BA%94%E7%94%A8B%E4%BC%9A%E5%87%BA%E7%8E%B0%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%EF%BC%9F"><span class="nav-number">6.3.1.</span> <span class="nav-text">6.3.1 无consumer group，应用A和应用B会出现什么情况？</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#6-3-2-%E4%B8%BA%E5%BA%94%E7%94%A8%E5%BB%BA%E7%AB%8Bconsumer-group%EF%BC%8C%E8%A7%82%E6%B5%8B%E5%BA%94%E7%94%A8A%E5%92%8C%E5%BA%94%E7%94%A8B%E7%9A%84%E6%83%85%E5%86%B5%E3%80%82"><span class="nav-number">6.3.2.</span> <span class="nav-text">6.3.2 为应用建立consumer group，观测应用A和应用B的情况。</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt=""
      src="https://www.linuxprobe.com/wp-content/uploads/2018/06/QQ%E5%9B%BE%E7%89%8720180625205006.png">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">一个非常专注技术总结与分享的博客</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">48</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">48</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yield-bytes</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">575k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">8:43</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/pjax/pjax.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/pisces.js"></script>


<script src="/blog/js/next-boot.js"></script>

<script src="/blog/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/blog/js/local-search.js"></script>













    <div id="pjax">
  

  

  

    </div>
</body>
</html>
