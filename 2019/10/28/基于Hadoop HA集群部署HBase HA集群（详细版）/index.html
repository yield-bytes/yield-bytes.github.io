<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yield-bytes.gitee.io","root":"/blog/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","Pisces | Gemini":240,"width":300,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1、前言&amp;#8195;&amp;#8195;前面的博客中链接已经给出Hadoop3.1.2和yarn的完整部署（但还不是高可用），此篇博客将给出Hadoop的高可用部署，以及HBase高可用，为之后应用数据层开发提供底层的BigTable支持。前面的文章，我们已经深入讨论的ZooKeeper这个中间件的原理以及分布式锁的实现，事实上zookeeper使用最广泛的场景是“选举”主从角色，Hadoop以及Hb">
<meta property="og:type" content="article">
<meta property="og:title" content="基于Hadoop HA集群部署HBase HA集群（详细版）">
<meta property="og:url" content="https://yield-bytes.gitee.io/blog/2019/10/28/%E5%9F%BA%E4%BA%8EHadoop%20HA%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2HBase%20HA%E9%9B%86%E7%BE%A4%EF%BC%88%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%89/index.html">
<meta property="og:site_name" content="yield-bytes">
<meta property="og:description" content="1、前言&amp;#8195;&amp;#8195;前面的博客中链接已经给出Hadoop3.1.2和yarn的完整部署（但还不是高可用），此篇博客将给出Hadoop的高可用部署，以及HBase高可用，为之后应用数据层开发提供底层的BigTable支持。前面的文章，我们已经深入讨论的ZooKeeper这个中间件的原理以及分布式锁的实现，事实上zookeeper使用最广泛的场景是“选举”主从角色，Hadoop以及Hb">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191019105428256.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191020121813446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191020122008421.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2019102012262488.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191020231354724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191020231738392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191020233357702.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191020233644573.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191021000759842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191021001137709.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/201910202357587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191021000048443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191023223724743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191024003258472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2019-10-28T14:26:17.000Z">
<meta property="article:modified_time" content="2020-02-03T10:04:38.000Z">
<meta property="article:tag" content="Hadoop集群">
<meta property="article:tag" content="HBase集群">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20191019105428256.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70">

<link rel="canonical" href="https://yield-bytes.gitee.io/blog/2019/10/28/%E5%9F%BA%E4%BA%8EHadoop%20HA%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2HBase%20HA%E9%9B%86%E7%BE%A4%EF%BC%88%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%89/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>基于Hadoop HA集群部署HBase HA集群（详细版） | yield-bytes</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/blog/atom.xml" title="yield-bytes" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">yield-bytes</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">分享与沉淀</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-th-large fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://gitee.com/yield-bytes" class="github-corner" title="Follow me on Gitee" aria-label="Follow me on Gitee" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yield-bytes.gitee.io/blog/2019/10/28/%E5%9F%BA%E4%BA%8EHadoop%20HA%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2HBase%20HA%E9%9B%86%E7%BE%A4%EF%BC%88%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://www.linuxprobe.com/wp-content/uploads/2018/06/QQ%E5%9B%BE%E7%89%8720180625205006.png">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="一个非常专注技术总结与分享的博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yield-bytes">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基于Hadoop HA集群部署HBase HA集群（详细版）
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-10-28 22:26:17" itemprop="dateCreated datePublished" datetime="2019-10-28T22:26:17+08:00">2019-10-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-03 18:04:38" itemprop="dateModified" datetime="2020-02-03T18:04:38+08:00">2020-02-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Hadoop/HBase/" itemprop="url" rel="index"><span itemprop="name">HBase</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>32k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>29 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h4 id="1、前言"><a href="#1、前言" class="headerlink" title="1、前言"></a>1、前言</h4><p>&#8195;&#8195;前面的博客中<a target="_blank" rel="noopener" href="https://blog.csdn.net/pysense/article/details/102490212">链接</a>已经给出Hadoop3.1.2和yarn的完整部署（但还不是高可用），此篇博客将给出Hadoop的高可用部署，以及HBase高可用，为之后应用数据层开发提供底层的BigTable支持。前面的文章，我们已经深入讨论的ZooKeeper这个中间件的原理以及分布式锁的实现，事实上zookeeper使用最广泛的场景是“选举”主从角色，Hadoop以及Hbase的高可用（主从架构）正是通过ZooKeeper的临时节点机制实现。<br>以下的配置会跳过Hadoop3.1.2的部署，仅给出ZooKeeper分布式物理方式部署、以及HBase的部署过程、测试结果。</p>
<h4 id="2、ZooKeeper与Hadoop、HBase的关系"><a href="#2、ZooKeeper与Hadoop、HBase的关系" class="headerlink" title="2、ZooKeeper与Hadoop、HBase的关系"></a>2、ZooKeeper与Hadoop、HBase的关系</h4><p>&#8195;&#8195;ZooKeeper作为协调器，在大数据组件中提供：管理Hadoop集群中的NameNode、HBase中HBaseMaster的选举，节点之间状态同步等。例如在HBase中，存储HBase的Schema，实时监控HRegionServer，存储所有Region的寻址入口，当然还有最常见的功能就是保证HBase集群中只有一个Master。</p>
<h4 id="3、Hadoop与HBase的关系"><a href="#3、Hadoop与HBase的关系" class="headerlink" title="3、Hadoop与HBase的关系"></a>3、Hadoop与HBase的关系</h4><p>&#8195;&#8195;完整的hadoop组件环境架构图<br><img src="https://img-blog.csdnimg.cn/20191019105428256.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<p>&#8195;&#8195;首先HBase是一个分布式的、面向列的开源数据库，正是业务数据需要列数据库的支持以及该数据库能够支持业务超大数据集扩展存储的需求，HBase当然作为中间件选型的首选。上图描述Hadoop组件生态中的各层系统。其中，HBase位于结构化存储层，Hadoop的HDFS为HBase提供了高可靠性、分布式的底层存储支持，Hadoop MapReduce、Spark为HBase提供了高性能的计算能力，Zookeeper为HBase提供了稳定选举服务和failover机制。<br>此外，Pig和Hive还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单。 Sqoop则为HBase提供了方便的RDBMS数据导入功能，使得传统数据库数据向HBase中迁移变的非常方便。<br>==（当然本blog也会针对Hbase的架构原理做出一篇文章讨论）==<br>&#8195;&#8195;其实，本博客有关大数据的多篇文章的内容，都是为了能够梳理出大数据多个组件全流程部署、架构原理、业务数据应用开发到BI的呈现的完整技术内容，以实现大数据库开发工程师必备的项目经历。</p>
<h4 id="4、架构资源规划"><a href="#4、架构资源规划" class="headerlink" title="4、架构资源规划"></a>4、架构资源规划</h4><table>
<thead>
<tr>
<th>nn</th>
<th>dn1</th>
<th>dn2</th>
</tr>
</thead>
<tbody><tr>
<td>1vcpu，2G内存</td>
<td>1vcpu，1G内存</td>
<td>1vcpu，1G内存</td>
</tr>
<tr>
<td>NameNode</td>
<td></td>
<td>NameNode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>DFSZKFailoverController</td>
<td>DFSZKFailoverController</td>
<td>DFSZKFailoverController</td>
</tr>
<tr>
<td>ResourceManager</td>
<td></td>
<td>ResourceManager</td>
</tr>
<tr>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
<tr>
<td>JobHistoryServer</td>
<td></td>
<td>JobHistoryServer</td>
</tr>
<tr>
<td>ZooKeeper</td>
<td>ZooKeeper</td>
<td>ZooKeeper</td>
</tr>
<tr>
<td>HBase master</td>
<td></td>
<td>HBase master</td>
</tr>
<tr>
<td>RegionServer</td>
<td>RegionServer</td>
<td>RegionServer</td>
</tr>
<tr>
<td>Hadoop版本、JDK版本、HBase版本、ZooKeeper版本参考如下：</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@nn opt]# ls</span><br><span class="line">hadoop-3.1.2   jdk1.8.0_161   </span><br><span class="line">hbase-2.1.7    zookeeper-3.4.14</span><br></pre></td></tr></table></figure>
<p>关于Hadoop与HBase的兼容性，官方已经给出<a target="_blank" rel="noopener" href="http://hbase.apache.org/book.html#_configuration_files">Hadoop version support matrix</a>，目前HBase2.1.x、HBase2.2.x支持Hadoop 3.1.1+（Tested to be fully-functional）。关于版本兼容分析，很多类似文章也有提到，但他们所提到的兼容比对情况已过时，故最佳途径应及时查阅官网最新发布的内容。</p>
<h4 id="5、ZooKeeper集群设置"><a href="#5、ZooKeeper集群设置" class="headerlink" title="5、ZooKeeper集群设置"></a>5、ZooKeeper集群设置</h4><h5 id="5-1-设置nn节点的zoo-conf"><a href="#5-1-设置nn节点的zoo-conf" class="headerlink" title="5.1 设置nn节点的zoo.conf"></a>5.1 设置nn节点的zoo.conf</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@nn conf]# pwd</span><br><span class="line">&#x2F;opt&#x2F;zookeeper-3.4.14&#x2F;conf</span><br><span class="line"># 拷贝zoo_sample.cfg并重命名为zoo.cfg ：</span><br><span class="line">[root@nn conf]# cp zoo_sample.cfg zoo.conf</span><br><span class="line"></span><br><span class="line"># 修改 zoo.cfg</span><br><span class="line">[root@nn conf] vi zoo.cfg</span><br><span class="line"># data目录需自行创建，添加：</span><br><span class="line">dataDir&#x3D;&#x2F;opt&#x2F;zookeeper-3.4.14&#x2F;data</span><br><span class="line"># 在该文件最后添加，指定zookeeper集群主机及端口，节点数必须为奇数</span><br><span class="line">server.1&#x3D;nn:2888:3888</span><br><span class="line">server.2&#x3D;dn1:2888:3888</span><br><span class="line">server.3&#x3D;dn2:2888:3888</span><br><span class="line"></span><br><span class="line"># 在&#x2F;opt&#x2F;zookeeper-3.4.14&#x2F;data目录下创建myid文件</span><br><span class="line">[root@nn data]# pwd</span><br><span class="line">&#x2F;opt&#x2F;zookeeper-3.4.14&#x2F;data</span><br><span class="line">[root@nn data]# touch myid</span><br><span class="line">[root@nn data]# ls</span><br><span class="line">myid</span><br><span class="line"># 文件内容为1，即表示当前节点为在zoo.cfg中指定的server.1</span><br></pre></td></tr></table></figure>
<h5 id="5-2-将zookeeper目录拷贝到dn1、dn2节点上，并更改对于的myid"><a href="#5-2-将zookeeper目录拷贝到dn1、dn2节点上，并更改对于的myid" class="headerlink" title="5.2 将zookeeper目录拷贝到dn1、dn2节点上，并更改对于的myid"></a>5.2 将zookeeper目录拷贝到dn1、dn2节点上，并更改对于的myid</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@nn opt]# scp -r zookeeper-3.4.14&#x2F; dn1:&#x2F;opt</span><br><span class="line">[root@nn opt]# scp -r zookeeper-3.4.14&#x2F; dn2:&#x2F;opt</span><br><span class="line"># 更改dn1 myid内容为2，dn2 myid内容为3</span><br></pre></td></tr></table></figure>
<h5 id="5-3-设置zk的全局环境变量"><a href="#5-3-设置zk的全局环境变量" class="headerlink" title="5.3 设置zk的全局环境变量"></a>5.3 设置zk的全局环境变量</h5><p>在三个节点上都要配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@nn opt] vi  &#x2F;etc&#x2F;profile</span><br><span class="line"># 新增</span><br><span class="line">ZOOKEEPER_HOME&#x3D;&#x2F;opt&#x2F;zookeeper-3.4.14 </span><br><span class="line">export   PATH&#x3D;$ZOOKEEPER_HOME&#x2F;bin:$PATH  </span><br></pre></td></tr></table></figure>
<p>source ~/.bash_profile</p>
<h5 id="5-4-启动zk集群"><a href="#5-4-启动zk集群" class="headerlink" title="5.4 启动zk集群"></a>5.4 启动zk集群</h5><p>在每个节点上运行<code>zkServer.sh start</code><br>查看三个节点的zk角色</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># nn节点</span><br><span class="line">[root@nn ~]# zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;opt&#x2F;zookeeper-3.4.14&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line"># dn1节点</span><br><span class="line">[root@dn1 opt]# zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;opt&#x2F;zookeeper-3.4.14&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line"></span><br><span class="line"># dn2节点</span><br><span class="line">[root@dn2 opt]# zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;opt&#x2F;zookeeper-3.4.14&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure>
<p>使用jps查看zk的进程QuorumPeerMain<br>QuorumPeerMain是zookeeper集群的启动入口类，用来加载配置启动QuorumPeer线程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@nn opt]# jps</span><br><span class="line">1907 Jps</span><br><span class="line">1775 QuorumPeerMain</span><br><span class="line"></span><br><span class="line">[root@dn1 opt]# jps</span><br><span class="line">16226 Jps</span><br><span class="line">16201 QuorumPeerMain</span><br><span class="line"></span><br><span class="line">[root@dn2 opt]# jps</span><br><span class="line">5824 QuorumPeerMain</span><br><span class="line">5861 Jps</span><br></pre></td></tr></table></figure>
<p>注意：如果某个节点使用jps命令后，没有QuorumPeerMain进程，一般是因为zk的端口号2181被占用，在<code>/opt/zookeeper-3.4.14</code>目录中，zookeeper.out执行日志会给相应的提示。<br>[root@nn zookeeper-3.4.14]# ls<br>bin              ivy.xml      README.md                 zookeeper-3.4.14.jar.sha1  zookeeper.out<br>….<br>以下为之前docker方式部署zk时占用了2181端口</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@dn2 zookeeper-3.4.14]# ss -tnlp |grep 2181</span><br><span class="line">LISTEN     0      128         :::2181                    :::*                   users:((&quot;docker-proxy&quot;,pid&#x3D;1499,fd&#x3D;4))</span><br><span class="line"># kill docker占用的2181进程，再重新启动zk即可。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="6、Hadoop-HA配置详细说明"><a href="#6、Hadoop-HA配置详细说明" class="headerlink" title="6、Hadoop HA配置详细说明"></a>6、Hadoop HA配置详细说明</h4><p>首先配置hadoop的jdk路径：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi hadoop-env.sh</span><br><span class="line">JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk1.8.0_161</span><br></pre></td></tr></table></figure>
<h5 id="6-1-core-site-xml-加入zk服务"><a href="#6-1-core-site-xml-加入zk服务" class="headerlink" title="6.1 core-site.xml 加入zk服务"></a>6.1 core-site.xml 加入zk服务</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!-- hdfs地址，单点模式值为namenode主节点名，本测试为HA模式，需设置为nameservice  的名字--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://hdapp&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">  &lt;!-- 这里的路径默认是NameNode、DataNode、JournalNode等存放数据的公共目录，也可以单独指定 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/opt/hadoop-3.1.2/tmp&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!--加入zk服务，不少于三个节点--&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn:2181,dn1:2181,dn2:2181&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!--设置web访问用户，否则web端浏览hdfs文件目录会提权限不足--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="6-2-hdfs-site-xml"><a href="#6-2-hdfs-site-xml" class="headerlink" title="6.2  hdfs-site.xml"></a>6.2  hdfs-site.xml</h5><p>因为要配置hadoop HA，因此这部分的属性项比较多，这部分内容参考<br><a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">Apache官网HA配置</a>，官网已经给出非常详细且易懂的描述。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!-- hadoop HA 配置开始 --&gt;</span><br><span class="line">  &lt;!-- 为namenode集群起一个services name，名字和core-site.xml的fs.defaultFS指定的一致 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.nameservices&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdapp&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line"> </span><br><span class="line">    &lt;!-- nameservice 包含哪些namenode，为各个namenode起名 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.namenodes.hdapp&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;nn,dn2&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 指定nn的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.rpc-address.hdapp.nn&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;nn:9000&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  </span><br><span class="line">      &lt;!-- 指定dn2的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.rpc-address.hdapp.dn2&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;dn2:9000&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  </span><br><span class="line">    &lt;!--名为nn的namenode的http地址和端口号，用来和web客户端通讯 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.http-address.hdapp.nn&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;nn:50070&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 名为dn2的namenode的http地址和端口号，用来和web客户端通讯 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.http-address.hdapp.dn2&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;dn2:50070&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- namenode间用于共享编辑日志的journal节点列表&#x2F;hdapp是表示日志存储的在hdfs上根路径，为多个HA可公用服务器进行数据存储，节约服务器成本 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;qjournal:&#x2F;&#x2F;nn:8485;dn1:8485;dn2:8485&#x2F;hdapp&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- journalnode 上用于存放edits日志的目录 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.journalnode.edits.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;opt&#x2F;hadoop-3.1.2&#x2F;tmp&#x2F;dfs&#x2F;journalnode&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定该集群出现故障时，是否自动切换到另一台namenode --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.automatic-failover.enabled.hdapp&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 客户端连接可用状态的NameNode所用的代理类 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.client.failover.proxy.provider.hdapp&lt;&#x2F;name&gt;  &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">    </span><br><span class="line">  &lt;!-- 一旦需要NameNode切换，使用两方式进行操作，优先使用sshfence --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.ha.fencing.methods&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;sshfence</span><br><span class="line">shell(&#x2F;bin&#x2F;true)</span><br><span class="line">&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 如果使用ssh进行故障切换，使用ssh通信时指定私钥所在位置 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;root&#x2F;.ssh&#x2F;id_rsa&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- ssh连接超时超时时间，30s --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;30000&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line"> &lt;!-- HA配置结束 --&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 设置 hdfs 副本数量，这里跟节点数量一致 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;3&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt; </span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>
<p>注意在sshfence设置中，若ssh用户名不是root，且ssh端口不是默认22，则需改为</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;sshfence([[my_hadoop][:31900]])&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br></pre></td></tr></table></figure>
<p>==以上设置非常重要，涉及sshfence能否正常切换主备hadoop服务==</p>
<p>官网给出自定义shell脚本去切换namenode进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">shell - run an arbitrary shell <span class="built_in">command</span> to fence the Active NameNode</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">The shell fencing method runs an arbitrary shell <span class="built_in">command</span>. It may be configured like so:</span></span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;shell(/path/to/my/script.sh arg1 arg2 ...)&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<h5 id="6-3-mapred-site-xml"><a href="#6-3-mapred-site-xml" class="headerlink" title="6.3 mapred-site.xml"></a>6.3 mapred-site.xml</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 采用yarn作为mapreduce的资源调度框架 --&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">   &lt;!-- 打开Jobhistory --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;nn:10020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定nn作为jobhistory服务器 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;nn:19888&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!--存放已完成job的历史日志 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/history/done&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!--存放正在运行job的历史日志 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/history/done_intermediate&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!--存放yarn stage的日志 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/history/staging&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> web上默认最多显示20000个历史的作业记录信息，这里设为1000个。</span></span><br><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;mapreduce.jobhistory.joblist.cache.size&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;1000&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.jobhistory.cleaner.enable&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 一天清理一次 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;mapreduce.jobhistory.cleaner.interval-ms&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;86400000&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 仅保留最近1周的job日志 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">     &lt;name&gt;mapreduce.jobhistory.max-age-ms&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;432000000&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>注意，这里加入yarn执行application（job）的日志记录进程，因为nn和dn2做了HA，所以nn、dn2节点都配上该jobhistory服务，dn1节点不需要。</p>
<h5 id="6-4-yarn-site-xml配置"><a href="#6-4-yarn-site-xml配置" class="headerlink" title="6.4  yarn-site.xml配置"></a>6.4  yarn-site.xml配置</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!-- 启用yarn HA高可用性 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定resourcemanager的名字，自行命名，跟服务器hostname无关 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hayarn&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 使用了2个resourcemanager,分别指定Resourcemanager的地址 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;rm1,rm2&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 指定nn节点为rm1 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 指定dn2节点为rm2  --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;dn2&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 指定当前机器nn作为主rm1 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;rm1&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 指定zookeeper集群机器 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn:2181,dn1:2181,dn2:2181&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- NodeManager上运行的附属服务，默认是mapreduce_shuffle --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 禁止启动一个线程检查每个任务正使用的物理内存量、虚拟内存量是否可用 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">   	&lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</span><br><span class="line">   	&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">   	&lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">   	&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h5 id="6-5-指定worker"><a href="#6-5-指定worker" class="headerlink" title="6.5 指定worker"></a>6.5 指定worker</h5><p>三个节点都设为datanode，在生产环境中，DD不要跟DN放在同一台服务器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@nn hadoop-3.1.2]# vi etc&#x2F;hadoop&#x2F;workers </span><br><span class="line">nn</span><br><span class="line">dn1</span><br><span class="line">dn2</span><br></pre></td></tr></table></figure>
<p>6.5 将/opt/hadoop-3.1.2/目录拷贝到dn1、dn2节点<br>(因为dn1不作为resourcemanager standby角色，因此在其yarn-site.xml删除)<br>nn节点作为resourcemanager 角色，因此在其yarn-site.xml，RM设为自己</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;rm1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>而dn2节点作为resourcemanager standby角色，因此在其yarn-site.xml，RM设为自己</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;rm2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h5 id="6-6-修改start-dfs-sh和-stop-dfs-sh文件"><a href="#6-6-修改start-dfs-sh和-stop-dfs-sh文件" class="headerlink" title="6.6  修改start-dfs.sh和 stop-dfs.sh文件"></a>6.6  修改start-dfs.sh和 stop-dfs.sh文件</h5><p>在/opt/hadoop-3.1.2/sbin/中，分别在 start-dfs.sh 和 stop-dfs.sh文件开始处添加如下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">HDFS_DATANODE_USER=root</span><br><span class="line">HDFS_DATANODE_SECURE_USER=hdfs</span><br><span class="line">HDFS_NAMENODE_USER=root</span><br><span class="line">HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">HDFS_ZKFC_USER=root</span><br><span class="line">HDFS_JOURNALNODE_USER=root</span><br><span class="line"><span class="meta">#</span><span class="bash"> 以上内容在三个节点上配置</span></span><br><span class="line"></span><br><span class="line">在start-yarn.sh和stop-yarn.sh文件头部添加如下命令</span><br><span class="line">​```shell</span><br><span class="line">YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">HDFS_DATANODE_SECURE_USER=yarn</span><br><span class="line">YARN_NODEMANAGER_USER=root</span><br><span class="line"><span class="meta">#</span><span class="bash"> 以上内容在三个节点上配置</span></span><br></pre></td></tr></table></figure>
<p>至此，以及完成hadoop层面的HA的配置文件，因为属性项很多，配置过程务必仔细核对，否则启动各种出错。下面将逐步验证各项组件启动情况</p>
<h4 id="7、集群启动"><a href="#7、集群启动" class="headerlink" title="7、集群启动"></a>7、集群启动</h4><p>在第5节内容中，三个节点zk的QuorumPeerMain进程已正常启动</p>
<h5 id="7-1-启动JournalNode进程"><a href="#7-1-启动JournalNode进程" class="headerlink" title="7.1 启动JournalNode进程"></a>7.1 启动JournalNode进程</h5><p>JournalNode服务三个节点启动都启动，因此，需在每个节点上单独运行启动命令，建议使用全局命令hdfs，否则得去每个节点的sbin目录下使用hadoop-daemon.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@nn ]# hdfs --daemon start journalnode</span><br><span class="line">[root@nn opt]# jps</span><br><span class="line">4889 JournalNode</span><br><span class="line">4987 Jps</span><br><span class="line">1775 QuorumPeerMain</span><br></pre></td></tr></table></figure>
<p>若启动正常，jps可以看三个节点都启动了相应进程</p>
<h5 id="7-2-格式化-NameNode和zkfc"><a href="#7-2-格式化-NameNode和zkfc" class="headerlink" title="7.2 格式化 NameNode和zkfc"></a>7.2 格式化 NameNode和zkfc</h5><p>这里的zkfc指：ZK Failover Controller daemon<br>==在NameNode的nn主节点上进行==</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@nn opt]# hdfs namenode -format</span><br><span class="line"><span class="meta">#</span><span class="bash"> 成功提示</span></span><br><span class="line">Storage directory /opt/hadoop-3.1.2/tmp/dfs/name has been successfully formatted.</span><br><span class="line"></span><br><span class="line">[root@nn opt]# hdfs zkfc -formatZK</span><br><span class="line"><span class="meta">#</span><span class="bash"> 成功提示</span></span><br><span class="line">: Successfully created /hadoop-ha/hdapp in ZK.</span><br></pre></td></tr></table></figure>
<p>==重要==<br>在备机dn2节点上执行fsimge元数据同步命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@dn2 sbin]# hdfs namenode -bootstrapStandby</span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以看到namenode主从服务信息</span></span><br><span class="line">=====================================================</span><br><span class="line">About to bootstrap Standby ID dn2 from:</span><br><span class="line">           Nameservice ID: hdapp</span><br><span class="line">        Other Namenode ID: nn</span><br><span class="line">  Other NN&#x27;s HTTP address: http://nn:50070</span><br><span class="line">  Other NN&#x27;s IPC  address: nn/192.188.0.4:9000</span><br><span class="line">             Namespace ID: 778809532</span><br><span class="line">            Block pool ID: **</span><br><span class="line">               Cluster ID:**</span><br><span class="line">           Layout version: -64</span><br><span class="line">       isUpgradeFinalized: true</span><br><span class="line">=====================================================</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> dn2节点通过http get去nn节点下载FsImage以便实现元数据同步</span></span><br><span class="line">namenode.TransferFsImage: Opening connection to http://nn:50070/imagetransfer?getimage=1&amp;txid=0&amp;storageInfo=-64:778809532:***:CID-594d1106-a909-4e60-8a2d-d54e264beee2&amp;bootstrapstandby=true</span><br><span class="line">***</span><br><span class="line">namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 391 bytes.</span><br></pre></td></tr></table></figure>

<h5 id="7-3-启动ZookeeperFailoverController、HDFS、YARN"><a href="#7-3-启动ZookeeperFailoverController、HDFS、YARN" class="headerlink" title="7.3 启动ZookeeperFailoverController、HDFS、YARN"></a>7.3 启动ZookeeperFailoverController、HDFS、YARN</h5><p>启动HA服务是有顺序的，需先启动ZKFC再启动HDFS，该服务管理hadoop的namenode主备切换；若先启动HDFS，则在未启动ZKFC进程之前，两个namenode都是standby模式，直到ZKFC启动后，HDFS才会正常进入HA主备模式。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1、启动主备切换服务，在nn、dn2分别执行</span></span><br><span class="line">[root@nn sbin]# hdfs --daemon start zkfc</span><br><span class="line">[root@dn2 sbin]# hdfs --daemon start zkfc</span><br><span class="line"><span class="meta">#</span><span class="bash"> DFSZKFailoverController进程</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2、只需在主节点nn上操作执行</span></span><br><span class="line">[root@nn sbin]# ./start-dfs.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证:nn,dn2显示NN、DN、JN，dn1显示DN、JN</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意namenode节点的tmp/dfs目录必须具有以下三个目录，否则namenode启动失败，提示相关目录不存在</span></span><br><span class="line">[root@dn2 dfs]# pwd</span><br><span class="line">/opt/hadoop-3.1.2/tmp/dfs</span><br><span class="line">[root@dn2 dfs]# ls</span><br><span class="line">data  journalnode  name</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3、只需在主节点nn上执行</span></span><br><span class="line">[root@nn sbin]# /start-yarn.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证：nn,dn2显示RN、NM，dn1显示NM</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="7-4-启动Application（job）History进程服务"><a href="#7-4-启动Application（job）History进程服务" class="headerlink" title="7.4  启动Application（job）History进程服务"></a>7.4  启动Application（job）History进程服务</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动JobHistoryServer</span></span><br><span class="line">mapred --daemon start  historyserver</span><br></pre></td></tr></table></figure>
<p>JobHistoryServer的作用：<br>可以通过历史服务器查看已经运行完的Mapreduce作业记录，比如用了多少个Map、用了多少个Reduce、作业提交时间、作业启动时间、作业完成时间等信息。</p>
<h5 id="7-5-使用命令或者web页面查看集群组件服务情况"><a href="#7-5-使用命令或者web页面查看集群组件服务情况" class="headerlink" title="7.5 使用命令或者web页面查看集群组件服务情况"></a>7.5 使用命令或者web页面查看集群组件服务情况</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在NameNode主节点nn上，用命令查看Namenode</span></span><br><span class="line">[root@nn opt]# hdfs haadmin -getServiceState nn</span><br><span class="line">active</span><br><span class="line">[root@nn opt]# hdfs haadmin -getServiceState dn2</span><br><span class="line">standby</span><br></pre></td></tr></table></figure>
<p>在<code>http://nn:50070</code>查看nn状态（最好使用Chrome查看，用Firefox查看Utilities栏目-Browse the file system没响应）<br><img src="https://img-blog.csdnimg.cn/20191020121813446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">在<code>http://dn2:50070</code>查看dn2状态<br><img src="https://img-blog.csdnimg.cn/20191020122008421.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在NameNode主节点nn上，用命令查看RM节点主备状态</span><br><span class="line">[root@nn opt]# yarn rmadmin -getServiceState rm1 </span><br><span class="line">standby</span><br><span class="line">[root@nn opt]# yarn rmadmin -getServiceState rm2</span><br><span class="line">active</span><br></pre></td></tr></table></figure>
<p>注意：这里显示是dn2（rm2）节点为active状态，当在浏览器输入<code>http://nn:8088</code>时，会自动被重定向到dn2的web服务：<code>http://dn2:8088/cluster</code><br><img src="https://img-blog.csdnimg.cn/2019102012262488.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5 id="7-6-hadoop主备切换测试"><a href="#7-6-hadoop主备切换测试" class="headerlink" title="7.6 hadoop主备切换测试"></a>7.6 hadoop主备切换测试</h5><p><strong>1）主备切换失败情况：</strong><br>在切换测试之前，请先检查Linux系统上有无安装一个fuser的工具<br>fuser：fuser可用于查询文件、目录、socket端口和文件系统的使用进程，并且可以使用fuser关闭进程，当文件系统umount报device busy时，常用到fuser查询并关闭使用相应文件系统的进程。<br>在6.2章节hdfs-site.xml配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  &lt;!-- 一旦需要NameNode切换，使用ssh方式或者shell进行操作 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.ha.fencing.methods&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;</span><br><span class="line">sshfence</span><br><span class="line">        shell(&#x2F;bin&#x2F;true)&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure>
<p>以上表示fencing的方法目前有两种，sshfence和shell<br>sshfence方法是指通过ssh登陆到active namenode节点并kill了该namenode进程，因此需设置ssh免密登陆，还要保证有杀掉namenode进程的权限，以保证hadoop集群在任何时候只有一个namenode节点处于active状态。<br>如果Linux系统没有fuser工具，那么sshfence执行会提示提示<br>==fuser: command not found==<br>==Fencing method org.apache.hadoop.ha.SshFenceByTcpPort(null) was unsuccessful.==<br>该日志路径是在dn2作为standby节点的日志目录下：<br><code>/opt/hadoop-3.1.2/logs/hadoop-root-zkfc-dn2.log</code><br>导致主备无法正常切换，可能出现脑裂（例如两个namenode都是active模式或者standby模式）</p>
<p><strong>2）解决方案：</strong><br>只需安装fuser工具即可<br><code>yum install psmisc -y</code>，安装之后，查看</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@dn2 logs]# ls &#x2F;usr&#x2F;sbin&#x2F;fuser </span><br><span class="line">&#x2F;usr&#x2F;sbin&#x2F;fuser</span><br></pre></td></tr></table></figure>

<p><strong>3）主备切换nn，dn2状态变更：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@nn sbin]# hdfs haadmin -getServiceState nn</span><br><span class="line">active</span><br><span class="line">[root@nn sbin]# hdfs haadmin -getServiceState dn2</span><br><span class="line">standby</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在主节点nn上，手动kill掉namenode进程，可以看到dn2立即变为active状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@nn sbin]# jps</span><br><span class="line">7424 NameNode</span><br><span class="line">5585 JournalNode</span><br><span class="line">5347 DataNode</span><br><span class="line">6024 ResourceManager</span><br><span class="line">5001 QuorumPeerMain</span><br><span class="line">25322 JobHistoryServer</span><br><span class="line">8922 Jps</span><br><span class="line">6652 DFSZKFailoverController</span><br><span class="line">6157 NodeManager</span><br><span class="line">[root@nn sbin]# kill -9 7424</span><br><span class="line">[root@nn sbin]# hdfs haadmin -getServiceState dn2</span><br><span class="line">active</span><br></pre></td></tr></table></figure>
<p>==以上kill了nn的namenode进程，再启动该进程，看看nn能否变为standby模式==</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@nn ~]# hdfs --daemon start namenode</span><br><span class="line">[root@nn ~]# hdfs haadmin -getServiceState nn</span><br><span class="line">standby</span><br><span class="line"># 或者使用强制转换主备命测试，注意因为是是测试环境，所以可以强制测试，如果已经在生产环境，请做好fsimage备份，否则可能主备的元数据不同步导致数据丢失。</span><br><span class="line">[root@nn ~]# hdfs haadmin -getAllServiceState                   </span><br><span class="line">nn:9000                                            active    </span><br><span class="line">dn2:9000                                           standby   </span><br><span class="line">[root@nn ~]# hdfs haadmin -transitionToStandby --forcemanual  nn</span><br><span class="line">[root@nn ~]# hdfs haadmin -getAllServiceState                   </span><br><span class="line">nn:9000                                            standby   </span><br><span class="line">dn2:9000                                           active   </span><br></pre></td></tr></table></figure>
<p>可以看到启动NN服务后，nn自身成功转为standby模式。<br>同理，RM的主备切换和恢复的过程跟上述一致，这里不再赘述。</p>
<p>==4）在zookeeper目录下查看hadoop HA建立的znode及其内容==<br>注意：以下说的zk节点是指znode，是一种类似目录的路径，不是指hadoop节点（服务器），注意区分。<br>[root@nn opt]# zkCli.sh </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看zk的根节点/有哪些节点</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 8] ls /</span><br><span class="line">[zookeeper, yarn-leader-election, hadoop-ha]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看hadoop-ha节点,可以看到子节点hdapp就是我们在hdfs-site.xml里配置的集群nameservices名称，若有多个集群，那么/hadoop-ha节点将有多个子节点</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 9] ls /hadoop-ha</span><br><span class="line">[hdapp]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 继续查看子节点hdapp是否还有子节点:可以看到这是都active状态节点的信息</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 11] ls /hadoop-ha/hdapp</span><br><span class="line">[ActiveBreadCrumb, ActiveStandbyElectorLock]</span><br><span class="line"><span class="meta">#</span><span class="bash"> ABC是持久节点，ASE是临时节点，nn、dn2都在ASE注册监听临时节点删除事件</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看主备选举的锁节点存放在哪个节点地址</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 7] get /hadoop-ha/hdapp/ActiveStandbyElectorLock</span><br><span class="line"></span><br><span class="line">hdappdn2dn2 �F(�&gt;</span><br><span class="line">***</span><br></pre></td></tr></table></figure>
<p>这里可以看到dn2节点抢到了ActiveStandbyElectorLock，因此作为active节点。<br>ActiveBreadCrumb持久节点用来防止脑裂设计，通过注册事件回调sshfence方法在另外一个节点上kill 掉NN进程<br>具体逻辑参考这篇文章的讨论：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8a6cc2d72062">文章链接</a>，内容还不错。</p>
<p>同样的yarn-leader-election选举处理逻辑也是借用zk节点特性和注册事件回调方法来实现，大体差不多。</p>
<p>至此负责底层分布式存储的Hadoop HA高可用已经完整实现，这部分是重点和难点，因此占了较大篇幅。此外这里还没给出HA管理员命令的使用以及理解：hdfs haadmin，不过这部分内容一般是hadoop集群运维部负责的工作，作为开发者的我们，也需要了解其中一部分内容。<br>接下来的关于HBase的主备配置则相对简单。</p>
<h4 id="8、HBase的HA配置"><a href="#8、HBase的HA配置" class="headerlink" title="8、HBase的HA配置"></a>8、HBase的HA配置</h4><h5 id="8-1-配置conf"><a href="#8-1-配置conf" class="headerlink" title="8.1  配置conf"></a>8.1  配置conf</h5><p>进入hbase-1.3.1/conf/目录，修改配置文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@nn conf]# pwd</span><br><span class="line">/opt/hbase-2.1.7/conf</span><br><span class="line">[root@nn conf]# pwd vi hbase-env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> The java implementation to use.  Java 1.8+ required.要求1.8以上的JDK</span></span><br><span class="line">export JAVA_HOME=/opt/jdk1.8.0_161</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 禁用HBase自带的Zookeeper，使用独立部署Zookeeper</span></span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure>
<p>以上配置在三个节点上配置（其实只需在nn和dn2 HMaster节点配置），为了避免以后需将dn1作为主节点时因之前漏了配置导致启动服务各种报错。</p>
<h5 id="8-2-配置hbase-site-xml"><a href="#8-2-配置hbase-site-xml" class="headerlink" title="8.2 配置hbase-site.xml"></a>8.2 配置hbase-site.xml</h5><p>关于hbase-site的详细内容，可以参考:<br>Apache HBase <a target="_blank" rel="noopener" href="http://hbase.apache.org/book.html">Getting Started</a>里面内容。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!-- 设置HRegionServers共享的HDFS目录，必须设为在hdfs-site中dfs.nameservices的值：hdapp，而且不能有端口号，该属性会让hmaster在hdfs集群上建一个/hbase的目录 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://hdapp/hbase&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 启用分布式模式 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 启用分布式模式时，以下的流能力加强需设为false --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定Zookeeper集群位置，值可以是hostname或者hostname:port --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn,dn1,dn2&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定独立Zookeeper安装路径 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/opt/zookeeper-3.4.14&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定ZooKeeper集群端口 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;2181&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>以上配置在三个节点配上</p>
<p>==注意：有部分有关HBaseHA配置技术博客文章中，有人会把hbase.rootdir配成以下形式==：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 直接指定hdfs的主节点</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdfs:&#x2F;&#x2F;nn:9000&#x2F;hbase&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 直接指定主的HMaster服务 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.master&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdfs:&#x2F;&#x2F;nn:60000&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>接着他们还会在<code>/opt/hbase-2.1.7/conf</code>创建一个文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi backup-master</span><br><span class="line"># 内容为hbase的备机服务器，例如本文的dn2节点</span><br><span class="line">dn2</span><br></pre></td></tr></table></figure>
<p>这种配法不是hbase HA的方式，是<a target="_blank" rel="noopener" href="http://hbase.apache.org/book.html#standalone_dist">官方配置</a>给出的单机模式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">5.1.1. Standalone HBase over HDFS</span><br><span class="line"></span><br><span class="line">A sometimes useful variation on standalone hbase has all daemons running inside the one JVM but rather than persist to the local filesystem, instead they persist to an HDFS instance.</span><br><span class="line">....</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdfs:&#x2F;&#x2F;namenode.example.org:8020&#x2F;hbase&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.cluster.distributed&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这种配法容易导致HBase服务退出：一旦nn节点从active状态切换为standby或者宕机，即使dn2对外提供hdfs服务，但hbase只认nn为active状态，并且会提示出错：<br> Operation category READ is not supported in state standby，也即没有可用的hdfs文件服务提供给HMaster进程去读，最后导致hbase异常退出。</p>
<h5 id="8-3-编辑regionservers"><a href="#8-3-编辑regionservers" class="headerlink" title="8.3 编辑regionservers"></a>8.3 编辑regionservers</h5><p>修改regionservers文件，因为当前是使用独立的Zookeeper集群，所以要指定RegionServers所在机器，按规划，三个节点都是RS角色：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@nn conf]# pwd</span><br><span class="line">/opt/hbase-2.1.7/conf</span><br><span class="line">[root@nn conf]# vi regionservers </span><br><span class="line">nn</span><br><span class="line">dn1</span><br><span class="line">dn2</span><br></pre></td></tr></table></figure>
<p>以上配置在三个节点配上</p>
<h5 id="8-4-创建hdfs-site-xml的软链到hbase的conf目录下"><a href="#8-4-创建hdfs-site-xml的软链到hbase的conf目录下" class="headerlink" title="8.4 创建hdfs-site.xml的软链到hbase的conf目录下"></a>8.4 创建hdfs-site.xml的软链到hbase的conf目录下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@nn conf]# ln -s /opt/hadoop-3.1.2/etc/hadoop/hdfs-site.xml /opt/hbase-2.1.7/conf/hdfs-site.xml</span><br><span class="line">[root@nn conf]# pwd</span><br><span class="line">/opt/hbase-2.1.7/conf</span><br><span class="line">[root@nn conf]# ll hdfs-site.xml </span><br><span class="line">lrwxrwxrwx. 1 root root 42 ** hdfs-site.xml -&gt; /opt/hadoop-3.1.2/etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure>
<p>该操作在三个节点上都要执行，这一环节的配置非常关键，HBase团队也给出相关解释：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Procedure: HDFS Client Configuration</span><br><span class="line">    Of note, if you have made HDFS client configuration changes on your Hadoop cluster, such as configuration directives for HDFS clients, as opposed to server-side configurations, you must use one of the following methods to enable HBase to see and use these configuration changes:</span><br><span class="line">        Add a pointer to your HADOOP_CONF_DIR to the HBASE_CLASSPATH environment variable in hbase-env.sh.</span><br><span class="line">        Add a copy of hdfs-site.xml (or hadoop-site.xml) or, better, symlinks, under $&#123;HBASE_HOME&#125;&#x2F;conf, or</span><br><span class="line">        if only a small set of HDFS client configurations, add them to hbase-site.xml.</span><br><span class="line">An example of such an HDFS client configuration is dfs.replication. If for example, you want to run with a replication factor of 5, HBase will create files with the default of 3 unless you do the above to make the configuration available to HBase.</span><br></pre></td></tr></table></figure>
<p>目的是为了HBase能够同步hdfs配置变化，例如上面提到当hdfs副本数改为5时，如果不创建这种配置映射，那么HBase还是按默认的3份去执行。</p>
<p>若缺少这个软链接，HBase启动集群服务有问题，部分RS无法启动！</p>
<h5 id="8-5-启动HBase集群遇到的问题"><a href="#8-5-启动HBase集群遇到的问题" class="headerlink" title="8.5 启动HBase集群遇到的问题"></a>8.5 启动HBase集群遇到的问题</h5><p>1） HMaster是否有顺序<br>首先，hbase的HA模式是工作在hdfs HA模式下，因此首先保证hdfs HA为正常状态。其次，HMaster无需在hdfs主节点上先启动，在standby节点也可以先启动，但每个HMaster的节点需独立运行start-hbase.sh。</p>
<p>2） 在启动HBase期间，相关出错的解决</p>
<p>A、HMaster进程启动正常，但是提示slf4j jar包存在多重绑定<br><code>SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/opt/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/opt/hbase-2.1.7/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</code><br>解决：其实该提示不影响HMaster和HRegionServer进程，可以选择忽略</p>
<p>B、启动HMaster短暂几秒后异常退出，日志提示找不到相关class：java.lang.NoClassDefFoundError: org/apache/htrace/SamplerBuilder<br>==解决办法==，将<code>htrace-core-3.1.0-incubating.jar </code>拷到lib目录下，<br> <code>$HBASE_HOME/ </code>为环境变量配置HBase路径:<br><code>cp $HBASE_HOME/lib/client-facing-thirdparty/htrace-core-3.1.0-incubating.jar $HBASE_HOME/lib/</code></p>
<p>C、两个节点的HMaster进程都正常运行，但所有HRegionServer进程会自动退出<br>原因：集群服务器之间的时间不同步导致，<br>解决办法：时间做同步</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"> #</span><span class="bash"> 将硬件时间写到系统时间</span></span><br><span class="line">[root@dn1 ~]# hwclock -s </span><br><span class="line">保存时钟</span><br><span class="line">[root@dn1 ~]# clock -w</span><br></pre></td></tr></table></figure>
<p>或者增加与master之间的时钟误差宽容度（不建议）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hbase.master.maxclockskew&lt;/name&gt;</span><br><span class="line">&lt;value&gt;150000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<h5 id="8-6-查看HBase集群信息"><a href="#8-6-查看HBase集群信息" class="headerlink" title="8.6  查看HBase集群信息"></a>8.6  查看HBase集群信息</h5><p>1）首先查看各个节点已经启动的服务<br>nn节点(HMaster、HRegionServer)：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@nn opt]# jps</span><br><span class="line">5585 JournalNode</span><br><span class="line">5347 DataNode</span><br><span class="line">23844 NameNode</span><br><span class="line">26839 Jps</span><br><span class="line">6024 ResourceManager</span><br><span class="line">25322 JobHistoryServer</span><br><span class="line">5001 QuorumPeerMain</span><br><span class="line">26026 HMaster</span><br><span class="line">6652 DFSZKFailoverController</span><br><span class="line">6157 NodeManager</span><br><span class="line">26191 HRegionServer</span><br></pre></td></tr></table></figure>
<p>dn1节点(HRegionServer)：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@dn1 opt]# jps</span><br><span class="line">12917 HRegionServer</span><br><span class="line">8074 JournalNode</span><br><span class="line">7979 DataNode</span><br><span class="line">7886 QuorumPeerMain</span><br><span class="line">8191 NodeManager</span><br><span class="line">13183 Jps</span><br></pre></td></tr></table></figure>
<p>dn2节点(HMaster、HRegionServer)：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@dn2 conf]# jps</span><br><span class="line">3200 NodeManager</span><br><span class="line">18416 Jps</span><br><span class="line">16339 NameNode</span><br><span class="line">25322 JobHistoryServer</span><br><span class="line">17827 HMaster</span><br><span class="line">2869 DataNode</span><br><span class="line">3973 DFSZKFailoverController</span><br><span class="line">17686 HRegionServer</span><br><span class="line">2698 QuorumPeerMain</span><br><span class="line">2970 JournalNode</span><br></pre></td></tr></table></figure>

<p>2）可通过web页面查看hbase主备情况<br>A、<code>http://nn:16010</code>显示nn为master，dn2为backup master，拥有3个RS<br><img src="https://img-blog.csdnimg.cn/20191020231354724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">B、<code>http://dn2:16010</code>显示dn2为backup master，当前active master为nn节点<br><img src="https://img-blog.csdnimg.cn/20191020231738392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">C、在zookeeper上查看</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@nn opt]# zkCli.sh</span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls &#x2F;</span><br><span class="line">[zookeeper, yarn-leader-election, hadoop-ha, hbase]</span><br></pre></td></tr></table></figure>
<p>以上可以看到hbase znode以及其他znode</p>
<p>继续查看/hbase子路径</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] ls &#x2F;hbase    </span><br><span class="line">[meta-region-server, rs, splitWAL,</span><br><span class="line">backup-masters, table-lock, flush-table-proc,</span><br><span class="line">master-maintenance, online-snapshot,</span><br><span class="line">switch, master, running, draining,</span><br><span class="line">namespace, hbaseid, table]</span><br></pre></td></tr></table></figure>
<p>以上可以看出hbase的集群服务器非常依赖zookeeper组件！！</p>
<p>查看hbase节点的RS路径列表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 4] ls &#x2F;hbase&#x2F;rs</span><br><span class="line">[dn2,16020,1571571550293, nn,16020,1571571549066, dn1,16020,1571571535046]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 5] get &#x2F;hbase&#x2F;rs&#x2F;dn1,16020,1571571535046</span><br><span class="line">�regionserver:16020&amp;�Q��PBU�&#125;�</span><br></pre></td></tr></table></figure>
<p>注意：在zkCli客户端get 相关path的内容因编码问题查看时会显示乱码，可通过hbase web端口查看zk内容<img src="https://img-blog.csdnimg.cn/20191020233357702.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20191020233644573.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5 id="8-7-HBase-主备切换测试"><a href="#8-7-HBase-主备切换测试" class="headerlink" title="8.7 HBase 主备切换测试"></a>8.7 HBase 主备切换测试</h5><p>1）kill掉 nn节点的HMaster，查看dn2是否转为active master</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@nn ~]# jps</span><br><span class="line">26026 HMaster</span><br><span class="line">[root@nn ~]# kill -9 26026</span><br></pre></td></tr></table></figure>
<p>在<code>http://dn2:16010</code>查看主备情况，可以看到nn节点down后，dn2成为master hbase节点<br><img src="https://img-blog.csdnimg.cn/20191021000759842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">2）将nn恢复Hbase服务，查看nn的HMaster是否为backup状态<br>在nn节点上执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@nn bin]# pwd</span><br><span class="line">/opt/hbase-2.1.7/bin</span><br><span class="line">[root@nn bin]# ./hbase-daemon.sh start master</span><br></pre></td></tr></table></figure>
<p>查看<code>http://nn:16010</code>，可以看到nn节点已经作为backup master，dn2节点为active master<br><img src="https://img-blog.csdnimg.cn/20191021001137709.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">在<code>http://dn2:16010</code>也可查看。</p>
<p>3）强制转换底层hdfs主备状态，查看hbase HA状态<br>把nn强制变为standby，hbase 主：nn，hbase：dn2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@nn conf]# hdfs haadmin -transitionToStandby --forcemanual  nn</span><br></pre></td></tr></table></figure>
<p>把dn2强制变为standby，hbase 主：nn，hbase：dn2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@nn conf]# hdfs haadmin -transitionToStandby --forcemanual  dn2</span><br></pre></td></tr></table></figure>
<p>hbase的主从状态不受底层hdfs主从变化影响，因为对于hbase来说，它只知道集群hdfs服务： hdfs://hdapp/hbase并没有改变。</p>
<p>至此，本文已经成功搭建了hadoop HA、yarn HA以及HBase HA服务，过程详细，积累不少经验，为之后本人给出大数据应用最核心内容之一——“数据应用开发”铺了很好的基础。</p>
<p>小结：所有服务的启动顺序如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">完整启动顺序</span><br><span class="line">1、分别在三台服务器上启动zookeeper</span><br><span class="line">[root@nn sbin]# zkServer.sh start</span><br><span class="line"># 三个服务器均可看到QuorumPeerMain进程</span><br><span class="line"></span><br><span class="line">2、在nn和dn2主节点上，启动zkfc</span><br><span class="line">[root@nn sbin]# hdfs --daemon start zkfc</span><br><span class="line"># 在nn和dn2主节点上，均可看到DFSZKFailoverController进程</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3、在主nn节点上，运行start-dfs.sh，无需在其他节点再运行该命令</span><br><span class="line">[root@nn sbin]# .&#x2F;start-dfs.sh </span><br><span class="line"># 可以看到NameNode、DataNode、journalnode服务</span><br><span class="line"></span><br><span class="line">4、在主nn节点上，运行start-yarn.sh，无需在其他节点再运行该命令</span><br><span class="line">[root@nn sbin]# .&#x2F;start-yarn.sh </span><br><span class="line"># 可以看到ResourceManager、NodeManager服务</span><br><span class="line"></span><br><span class="line">5、在nn、dn2主节点上，启动JobHistoryServer服务</span><br><span class="line">[root@nn bin]#  mapred --daemon start  historyserver</span><br><span class="line"># jps看到JobHistoryServer服务</span><br><span class="line"></span><br><span class="line">6、在nn、dn2主节点上，启动hbase服务</span><br><span class="line"></span><br><span class="line"># nn节点启动hbase</span><br><span class="line">[root@nn bin]# .&#x2F;start-hbase.sh</span><br><span class="line"></span><br><span class="line"># 在dn2节点上启动hbase，</span><br><span class="line">[root@dn2 bin]# .&#x2F;start-hbase.sh</span><br><span class="line"># HMaster\HRegionServer</span><br></pre></td></tr></table></figure>

<h4 id="9、HBase在hdfs创建的目录"><a href="#9、HBase在hdfs创建的目录" class="headerlink" title="9、HBase在hdfs创建的目录"></a>9、HBase在hdfs创建的目录</h4><p><img src="https://img-blog.csdnimg.cn/201910202357587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">/hbase目录下的内容<br><img src="https://img-blog.csdnimg.cn/20191021000048443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">关于这些文件的解释以及作用，将在下一篇HBase架构原理给出。</p>
<h4 id="10、在HBase创建table测试"><a href="#10、在HBase创建table测试" class="headerlink" title="10、在HBase创建table测试"></a>10、在HBase创建table测试</h4><p>这部分内容回到大家相对熟悉的数据库知识领域，本节内容仅提供基础demo用法，关于HBase的数据结构以及架构原理，本博客将在另外一篇文章进行深入讨论。<br>以下company表为例进行基本操作，该表包含staff_info和depart_info两个列簇，表结构如下所示：<br><img src="https://img-blog.csdnimg.cn/20191023223724743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">以下为基本的hbase使用：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入HBase进行交互式操作</span></span><br><span class="line">[root@nn ~] hbase shell</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建company表，从这里即可看出列数据库的优势，无需预先定义列，表结构是松散灵活的，之后想加多少列都行。</span></span><br><span class="line">hbase(main):&gt; create &#x27;company&#x27;,&#x27;staff_info&#x27;,&#x27;depart_info&#x27;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看当前HBase有哪些表</span></span><br><span class="line">hbase(main):&gt; list</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">获得表company的描述信息</span></span><br><span class="line">hbase(main):&gt; describe &#x27;company&#x27;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看全表数据,相当于selec * from company</span></span><br><span class="line">hbase(main):&gt; scan &#x27;t_user&#x27;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 往表插入数据，语法 put  <span class="string">&#x27;t&#x27;</span> ,<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;v&#x27;</span>  (表名，行rowkey，列簇：具体列，值)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 第1行记录</span></span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;staff_info:name&#x27;,&#x27;Aery&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;staff_info:age&#x27;,&#x27;25&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;staff_info:sex&#x27;,&#x27;Male&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;depart_info:name&#x27;,&#x27;Develop&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;depart_info:level&#x27;,&#x27;10&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;depart_info:inner_tel&#x27;,&#x27;109&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 第2行记录</span></span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;staff_info:name&#x27;,&#x27;Bery&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;staff_info:age&#x27;,&#x27;23&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;staff_info:sex&#x27;,&#x27;Female&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;depart_info:name&#x27;,&#x27;HR&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;depart_info:level&#x27;,&#x27;9&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R1&#x27;,&#x27;depart_info:inner_tel&#x27;,&#x27;108&#x27;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 第3行记录</span></span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;staff_info:name&#x27;,&#x27;Cery&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;staff_info:age&#x27;,&#x27;26&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;staff_info:sex&#x27;,&#x27;female&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;depart_info:name&#x27;,&#x27;Market&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;depart_info:level&#x27;,&#x27;9&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;depart_info:inner_tel&#x27;,&#x27;107&#x27;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 第4行记录</span></span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;staff_info:name&#x27;,&#x27;Dery&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;staff_info:age&#x27;,&#x27;27&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;staff_info:sex&#x27;,&#x27;Male&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;depart_info:name&#x27;,&#x27;Finance&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;depart_info:level&#x27;,&#x27;9&#x27;</span><br><span class="line">hbase(main):&gt; put &#x27;company&#x27; ,&#x27;R2&#x27;,&#x27;depart_info:inner_tel&#x27;,&#x27;106&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取数据，有以下几种方式</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里cell已经包含timestamp和value</span></span><br><span class="line">hbase(main):038:0&gt; get &#x27;company&#x27;,&#x27;R1&#x27;</span><br><span class="line">COLUMN              cell                                                         </span><br><span class="line"> depart_info:inner_tel  timestamp=**, value=108                              </span><br><span class="line"> depart_info:level      timestamp=**, value=9                                </span><br><span class="line"> depart_info:name       timestamp=**, value=HR                               </span><br><span class="line"> staff_info:age         timestamp=**, value=23                               </span><br><span class="line"> staff_info:name        timestamp=**, value=Bery                             </span><br><span class="line"> staff_info:sex         timestamp=**, value=Female                           </span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0427 seconds    </span><br><span class="line">                        </span><br><span class="line"></span><br><span class="line">hbase(main):039:0&gt; get &#x27;company&#x27;,&#x27;R2&#x27;,&#x27;staff_info&#x27;</span><br><span class="line">COLUMN                  CELL  </span><br><span class="line"> staff_info:age         timestamp=**  value=27                               </span><br><span class="line"> staff_info:name        timestamp=**, value=Dery                             </span><br><span class="line"> staff_info:sex         timestamp=**, value=Male                             </span><br><span class="line">1 row(s)</span><br><span class="line"></span><br><span class="line">hbase(main):&gt; get &#x27;company&#x27;,&#x27;R1&#x27;,&#x27;staff_info:age&#x27;</span><br><span class="line"></span><br><span class="line">COLUMN                  CELL                                                          </span><br><span class="line"> staff_info:age         timestamp=**, value=23                               </span><br><span class="line">1 row(s)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 计算company rowkey数目</span></span><br><span class="line">hbase(main):041:0&gt; count &#x27;company&#x27;</span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.1696 seconds</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除R2中的部门信息的level列                                                                    hbase(main):072:0&gt; delete <span class="string">&#x27;company&#x27;</span>,<span class="string">&#x27;R2&#x27;</span>,<span class="string">&#x27;depart_info:level&#x27;</span></span> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 清空表内容</span></span><br><span class="line"><span class="meta">hbase(main)&gt;</span><span class="bash"> truncate <span class="string">&#x27;company&#x27;</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 禁用表，之后drop表才有效</span></span><br><span class="line">hbase(main):&gt; disable &#x27;company&#x27;</span><br><span class="line">hbase(main):&gt; drop &#x27;company&#x27;</span><br><span class="line">hbase(main):&gt; exists &#x27;company&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>company表的信息也可以在HMaster web端查看<br><img src="https://img-blog.csdnimg.cn/20191024003258472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3B5c2Vuc2U=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">     &#8195;&#8195;以上为基本的hbase表操作，如果用shell的方式开发hbase数据应用，效率是非常低的，就像直接在mysql的shell写复杂sql、在Oracle的shell写sql那样，虽然很raw，但不友好。而对于mysql的sql开发，大家会用workbench或者DBeaver；对于Oracle的开发，大家会用PL/SQL Developer；在程序业务逻辑开发层面，大家会引入DB-API 第三方库实现业务逻辑开发。<br>那么对于HBase分布式数据库的开发，需要用到Hive工具。<br>&#8195;&#8195;Hive是建立在 Hadoop 上的数据仓库基础构架，它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），通过Hive，用户可以类 SQL 查询语言（又称 HQL）去“操作Hbase上的数据”，省去独自开发mapper 和 reducer 来处理计算任务（当然复杂的业务逻辑还是需要开发mapper和reducer）。<br>&#8195;&#8195;本博客将在后面的文章中，引入Hive组件，配合HBase进行某个主题的大数据实际项目开发。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/Hadoop%E9%9B%86%E7%BE%A4/" rel="tag"># Hadoop集群</a>
              <a href="/blog/tags/HBase%E9%9B%86%E7%BE%A4/" rel="tag"># HBase集群</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2019/10/27/MapReduce%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/" rel="prev" title="MapReduce设计原理">
      <i class="fa fa-chevron-left"></i> MapReduce设计原理
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2019/11/02/HBase%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/" rel="next" title="HBase架构分析">
      HBase架构分析 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">1、前言</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81ZooKeeper%E4%B8%8EHadoop%E3%80%81HBase%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">2.</span> <span class="nav-text">2、ZooKeeper与Hadoop、HBase的关系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81Hadoop%E4%B8%8EHBase%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">3.</span> <span class="nav-text">3、Hadoop与HBase的关系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81%E6%9E%B6%E6%9E%84%E8%B5%84%E6%BA%90%E8%A7%84%E5%88%92"><span class="nav-number">4.</span> <span class="nav-text">4、架构资源规划</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5%E3%80%81ZooKeeper%E9%9B%86%E7%BE%A4%E8%AE%BE%E7%BD%AE"><span class="nav-number">5.</span> <span class="nav-text">5、ZooKeeper集群设置</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#5-1-%E8%AE%BE%E7%BD%AEnn%E8%8A%82%E7%82%B9%E7%9A%84zoo-conf"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 设置nn节点的zoo.conf</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-%E5%B0%86zookeeper%E7%9B%AE%E5%BD%95%E6%8B%B7%E8%B4%9D%E5%88%B0dn1%E3%80%81dn2%E8%8A%82%E7%82%B9%E4%B8%8A%EF%BC%8C%E5%B9%B6%E6%9B%B4%E6%94%B9%E5%AF%B9%E4%BA%8E%E7%9A%84myid"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 将zookeeper目录拷贝到dn1、dn2节点上，并更改对于的myid</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-3-%E8%AE%BE%E7%BD%AEzk%E7%9A%84%E5%85%A8%E5%B1%80%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">5.3.</span> <span class="nav-text">5.3 设置zk的全局环境变量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-4-%E5%90%AF%E5%8A%A8zk%E9%9B%86%E7%BE%A4"><span class="nav-number">5.4.</span> <span class="nav-text">5.4 启动zk集群</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6%E3%80%81Hadoop-HA%E9%85%8D%E7%BD%AE%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E"><span class="nav-number">6.</span> <span class="nav-text">6、Hadoop HA配置详细说明</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#6-1-core-site-xml-%E5%8A%A0%E5%85%A5zk%E6%9C%8D%E5%8A%A1"><span class="nav-number">6.1.</span> <span class="nav-text">6.1 core-site.xml 加入zk服务</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-2-hdfs-site-xml"><span class="nav-number">6.2.</span> <span class="nav-text">6.2  hdfs-site.xml</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-3-mapred-site-xml"><span class="nav-number">6.3.</span> <span class="nav-text">6.3 mapred-site.xml</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-4-yarn-site-xml%E9%85%8D%E7%BD%AE"><span class="nav-number">6.4.</span> <span class="nav-text">6.4  yarn-site.xml配置</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-5-%E6%8C%87%E5%AE%9Aworker"><span class="nav-number">6.5.</span> <span class="nav-text">6.5 指定worker</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-6-%E4%BF%AE%E6%94%B9start-dfs-sh%E5%92%8C-stop-dfs-sh%E6%96%87%E4%BB%B6"><span class="nav-number">6.6.</span> <span class="nav-text">6.6  修改start-dfs.sh和 stop-dfs.sh文件</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7%E3%80%81%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8"><span class="nav-number">7.</span> <span class="nav-text">7、集群启动</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#7-1-%E5%90%AF%E5%8A%A8JournalNode%E8%BF%9B%E7%A8%8B"><span class="nav-number">7.1.</span> <span class="nav-text">7.1 启动JournalNode进程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-2-%E6%A0%BC%E5%BC%8F%E5%8C%96-NameNode%E5%92%8Czkfc"><span class="nav-number">7.2.</span> <span class="nav-text">7.2 格式化 NameNode和zkfc</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-3-%E5%90%AF%E5%8A%A8ZookeeperFailoverController%E3%80%81HDFS%E3%80%81YARN"><span class="nav-number">7.3.</span> <span class="nav-text">7.3 启动ZookeeperFailoverController、HDFS、YARN</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-4-%E5%90%AF%E5%8A%A8Application%EF%BC%88job%EF%BC%89History%E8%BF%9B%E7%A8%8B%E6%9C%8D%E5%8A%A1"><span class="nav-number">7.4.</span> <span class="nav-text">7.4  启动Application（job）History进程服务</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-5-%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E6%88%96%E8%80%85web%E9%A1%B5%E9%9D%A2%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6%E6%9C%8D%E5%8A%A1%E6%83%85%E5%86%B5"><span class="nav-number">7.5.</span> <span class="nav-text">7.5 使用命令或者web页面查看集群组件服务情况</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-6-hadoop%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E6%B5%8B%E8%AF%95"><span class="nav-number">7.6.</span> <span class="nav-text">7.6 hadoop主备切换测试</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8%E3%80%81HBase%E7%9A%84HA%E9%85%8D%E7%BD%AE"><span class="nav-number">8.</span> <span class="nav-text">8、HBase的HA配置</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#8-1-%E9%85%8D%E7%BD%AEconf"><span class="nav-number">8.1.</span> <span class="nav-text">8.1  配置conf</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8-2-%E9%85%8D%E7%BD%AEhbase-site-xml"><span class="nav-number">8.2.</span> <span class="nav-text">8.2 配置hbase-site.xml</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8-3-%E7%BC%96%E8%BE%91regionservers"><span class="nav-number">8.3.</span> <span class="nav-text">8.3 编辑regionservers</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8-4-%E5%88%9B%E5%BB%BAhdfs-site-xml%E7%9A%84%E8%BD%AF%E9%93%BE%E5%88%B0hbase%E7%9A%84conf%E7%9B%AE%E5%BD%95%E4%B8%8B"><span class="nav-number">8.4.</span> <span class="nav-text">8.4 创建hdfs-site.xml的软链到hbase的conf目录下</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8-5-%E5%90%AF%E5%8A%A8HBase%E9%9B%86%E7%BE%A4%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">8.5.</span> <span class="nav-text">8.5 启动HBase集群遇到的问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8-6-%E6%9F%A5%E7%9C%8BHBase%E9%9B%86%E7%BE%A4%E4%BF%A1%E6%81%AF"><span class="nav-number">8.6.</span> <span class="nav-text">8.6  查看HBase集群信息</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8-7-HBase-%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E6%B5%8B%E8%AF%95"><span class="nav-number">8.7.</span> <span class="nav-text">8.7 HBase 主备切换测试</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9%E3%80%81HBase%E5%9C%A8hdfs%E5%88%9B%E5%BB%BA%E7%9A%84%E7%9B%AE%E5%BD%95"><span class="nav-number">9.</span> <span class="nav-text">9、HBase在hdfs创建的目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10%E3%80%81%E5%9C%A8HBase%E5%88%9B%E5%BB%BAtable%E6%B5%8B%E8%AF%95"><span class="nav-number">10.</span> <span class="nav-text">10、在HBase创建table测试</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt=""
      src="https://www.linuxprobe.com/wp-content/uploads/2018/06/QQ%E5%9B%BE%E7%89%8720180625205006.png">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">一个非常专注技术总结与分享的博客</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">48</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">48</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yield-bytes</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">577k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">8:44</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/pjax/pjax.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/pisces.js"></script>


<script src="/blog/js/next-boot.js"></script>

<script src="/blog/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/blog/js/local-search.js"></script>













    <div id="pjax">
  

  

  

    </div>
</body>
</html>
